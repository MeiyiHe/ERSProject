abkTalkNote
SLIDE: Title
Thank you for being my committee professors. My topic for today’s presentation is “Improved physical design and signoff methodologies for better design quality”.

SLIDE: Publications
This slide shows my publications. In red are the papers I will cover in today’s talk.

SLIDE: Publications
This slide shows my publications and posters.  

SLIDE: Challenges in Existing Physical Design/Signoff
First of all, this slide summarizes the future challenges in physical design and signoff. 

Due to small geometries and manufacturing-induced design rules, physical design becomes difficult in advanced nodes. One example is that placement and routing optimization must comprehend pin-accessibility issue. 

As we are towards the end of CMOS scaling, design-based equivalent scaling is important. However, this will increase the design complexity and make physical design difficult. Some examples are three-dimensional integration, approximate computing and resilient designs. 

In addition, corner explosion is another design challenge. More specifically, we have operating modes such as turbo mode and nominal mode. We have device corners and interconnect corners. 

Driven by IoT applications, there is low-power requirement in IC designs. The low-power techniques such as multiple power domain, clock gating, power gating also increase complexity and difficulty in physical design. 

More importantly, unable to address these future challenges will lead to degraded design quality.

SLIDE: In This Presentation
In my works, I pursue improved physical design optimization and signoff to achieve better tradeoffs among performance, power and area in future VLSI designs. 

In this presentation, I will cover three topics. 

I will first describe a novel mixed cell-height implementation in advanced nodes. 

Then, I will describe min-cost resilient design implementation. 

Last, I will show my work on design-stage optimizations for mix-and-match die stacking in 3DICs.

SLIDE: Mixed Cell-Height Placement in Advanced Nodes
I will first describe our work of mixed cell-height placement in advanced node. 

SLIDE: Mixed Cell Height Implementation (!)
In advanced nodes, cells are designed with different heights. For example, cells have different numbers of fins in FinFET technology. Larger cell height offers better timing, but at the cost of area and power. Small cell height has smaller area and power per gate, but has large delay and can result in large number of buffers for a given performance target. 

Unlike conventional device, in FinFET, the conducting channel is wrapped by a thin silicon “fin”. The wrap-around gate structure provides a better electrical control over the channel, and thus offers reduced leakage current. 

This figure shows the area-delay tradeoff of buffers and inverters at 28LP technology. In red are 12T cells and in blue are 8T cells. We can clearly see they that have different area-delay tradeoffs. 

So, one question arises is that “can we mix cells of different heights to have a better tradeoff between performance, area and power, and to achieve a better design quality?” 

SLIDE: Motivation of Mixing Cell Heights
We first compare the area and timing of designs synthesized with 12T-only, 8T-only and mixed cell heights in 28LP technology. Figures show the comparison. We can see that mixing cell heights can achieve more than 14% area reduction compared to 12T-only and 8T-only designs. 

So mixing cell heights in a design is quite promising. But no existing flow can offer block-level mixed cell-height optimization. 

Also, there is “chicken-and-egg” loop for such an optimization, where heights of cell rows are defined during floorplan stage before placement. But the choices of cell heights highly depend the on the placement solution. 

SLIDE: Also, There is Cost of Mixing Cell Heights
Further, mixing cell heights is not free. “Interface area” must be inserted to align regions with different cell heights. So there is area cost. 

As an example shown in the figure, the width of the interface area is four sites to align cell rows with different heights horizontally. And the height of the interface area is one M2 pitch to align cell rows with different heights vertically. 

A mixed cell-height optimization must comprehend these cost and challenges.

SLIDE: Overall Flow
This slide shows our overall flow for mixed cell-height implementation. 

We first synthesize design with libraries of all available cell heights. 

Then, we perform placement of cells with modified cell LEF such that all cells have the same height. But we scale cell widths to maintain the same cell area. The figure shows one example. Such modification enables optimization with commercial P&R tools and resolves the “chicken-and-egg” loop between placement and cell height selection. 

Then we partition the floorplan into regions with a specific cell height and legalize the placement solution so that each region contains only the cells with the same height. I will discuss the details in the following slides.

Afterwards, we revise the floorplan with determined cell heights from partitioning solution and insert interface area. 

Then, we map cells back to their original heights and widths, and place them onto the updated cell rows. 

Last, we perform the routing and routing optimization using commercial tools.

An example of the flow will be given in the next slide.

SLIDE: Optimization Flow
This slide shows an example of our optimization flow on design AES. In blue are 8T cells and in red are 12T cells. First figure shows the initial placement where with modified LEF, cells are “freely” placed with a commercial placer. 

The second figure shows the partitioning solution based on dynamic programming. The yellow lines are cuts. 

The third figure shows the legalized placement solution. 

In the last two figures, we update the floorplan and map cells onto the updated cell rows. Note that in the last two figures, the floorplan contains both 12T cell rows and 8T cell rows.  

SLIDE: Floorplan Partitioning and Region Definition
We partition die area into rectangular regions with different cell heights based on dynamic programming. To formulate the dynamic programming, we first define the cost of a region as the total area of minority cells within the region. As an example in the figure, the cost of a 12T region is the blue area within the region. We then sweep cut number (k), coordinates of a region, and all possible horizontal and vertical cuts to select the optimal solution with dynamic programming. The pseudo code is given here. 






SLIDE: Timing-Aware Placement Legalization
Based on the partitioning solution, we legalize the placement with an iterative optimization. Our goal here is to have a legal placement such that a 12T region contains only 12T cells and an 8T region contains only 8T cells. We use two knobs in our iterative optimization. First one is cell displacement, as an example, we move a 12T cell from an 8T region to a 12T region. Second one is cell-height swapping, for example, we size a 12T cell in an 8T region to an 8T cell master. The figure shows our optimization framework. We build our optimizer in C++ and use TCL socket to interact with commercial P&R tool. To reduce the runtime of timing analysis, we also construct an internal timer based several delay models. 

SLIDE: Mapping Cells to Original Heights/Widths
Recall that in the initial placement, we modify cell LEF such that all cells have the same height, and scale cells widths to maintain the same cell area. In the last stage, with the updated floorplan, we need to scale cells back to their original heights and widths and map them to updated cell rows. 
We illustrate our flow with a special case – a 2D mesh. Based on a previous work on graph embedding, we can map cells to new cell rows in the updated floorplan with the maximum wirelength increase by (r + 1/r) times. Here r is the ratio between original cell height to the minimum cell height. An example of such graph embedding is shown in the figure. The initial graph is a 5x4 mesh, with wirelength = 1 for each edge. The vertical edges are not shown. Then we embed the graph into the right figure, which is a 4x5 mesh. In the new graph, the wirelength of a vertical edge is 1.25, the wirelength of a horizontal edge is 0.8. 

SLIDE: Benefits from Mixing Cell Heights
The figure shows our experimental results at the post-routing stage. We compare the performance-area tradeoff of our mixed cell-height design with those of 8T- and 12T-only designs. We observe 25% area reduction compared to 12T-only case and 20% performance improvement compared to 8T-only case. 

Our future works includes mixed cell-height clock tree synthesis and application of mixed cell-height optimization in 3DICs.





SLIDE: Low-Cost Resilient Design Implementation
Now, I will describe our work of the low-cost resilient design implementation.

SLIDE: Background: Resilient Design
First, what is a resilient design? A resilient design can detect and recover from timing errors. Therefore, it ensures correct operation with dynamic variations, such as supply voltage drop, temperature fluctuation, and cross-coupling. In addition, resilient design trades off between design robustness versus design quality. Last, by allowing timing errors, resilient design also improves performance through timing speculation. The bottom figure shows the energy comparison between conventional and resilient designs at different supply voltages. In conventional designs, timing violations lead to failure. Therefore, it is risky for voltage downscaling. Since resilient designs are able to detect and recover from timing errors, downscaling of supply voltage leads to power reduction. In this example, we see the energy gap can be 15%.     
SLIDE: Cost of Resilience is High
Although there are significant benefits in resilient designs, the cost of resilience is high. As shown in the figures, resilient designs typically have additional circuits to detect timing errors, which inccur area and power penalties. Further, recovery from timig errors requires additional cycles, which causes throughput degradation. Also, error-tolerant flip-flops require large hold margin, which leads to short-path padding cost. 
The table summarizes the cost of resilience for Razor, Razor-Lite and TIMBER. We can observe that the area and power penalties are quite high. Therefore, the goal in this work is to implement resilient designs such that their benefits overweigh their costs. 

SLIDE: Resilience Cost Reduction Problem
We define the resilience cost reduction problem as – given an RTL design, throughput requirement, and error-tolerant registers, we implement design to minimize energy, 
We estimate the design energy based on this equation. We further estimate throughput based on the equation shown in red dotted box, in which ER is the error rate; r is the number of cycles required to recover from an error; T is the clock period. 

SLIDE: Scope of This Work
Most of previous works identify and optimize timing-critical and/or most frequently exercised paths instead of all paths to reduce resilience cost. But they ignore the tradeoff between resilience cost versus cost of datapath optimization. For example, when the number of Razor FFs reduces, the resilience cost reduces; but power and area of fanin circuits will increase. 
This figure shows one example where we reduce the number of Razor flip-flops from 300 to zero. Red curve indicates the resilience cost, which includes power overhead of Razor flip-flops and throughput penalty. The blue curve indicates energy of non-resilient part of the design. And the green curve is the total energy. We see in this example that the total energy shows a bucket-shape curve due to tradeoffs between cost of resilience and cost of datapath optimization. In this work, we minimize the total energy using such tradeoff.   

SLIDE: Overview of Our Methodology
This slide shows an overview of our methodology. Our flow starts with a pure-resilience solution, where all endpoints use error-tolerant flip-flops. Then we iteratively apply optimizations to reduce resilience cost. 
We use two optimizations. First one is low-cost timing margin insertion. We call it as selective-endpoint optimization. In this optimization, we selectively increase margin at endpoints with timing violation, but at a low cost on datapath. Second, we use clock skew optimization to migrate timing slacks to endpoint with timing violation. 
With the increased slacks, we are able to replace error-tolerant flip-flops to normal flip-flops and reduce the resilience cost. 












SLIDE: Overall Optimization Flow
This slide shows the overall optimization flow. We iteratively optimize with selective-endpoint optimization and clock skew optimization. We start with an initial placement assuming that all endpoints use error-tolerant flip-flops. The right figure shows an example of slack distribution. We then insert timing margins on K paths based on sensitivity function. For enpoints which have larger slack than the required safety margin, we replace the error-tolerant flip-flops with normal flip-flops to reduce area and power penalties. We then apply activity-aware clock skew optimization to further optimize timing slacks. We keeps iterating between selective-endpoint optimization and clock skew optimization. After each iteration, we check whether the energy is less than the minimum energy ever seen. If so, we save the solution. The optimization flow stops when all endpoints are optimized.
In the following discussion I will give details on selective-endpoint optimization and clock skew optimization. 

SLIDE: Selective-Endpoint Optimization
In the selective-endpoint optimization, we optimize the fanin cone with tighter timing constraints. Such optimization allows replacement of error-tolerant flip-flops with normal flip-flops. In other words, selective-endpoint optimization trades off cost of resilience versus cost of data-path optimization. 
Two questions arise for the selective-endpoint optimization. First, which endpoint to be optimized? The second, how many endpoints should be optimized? 

SLIDE: Sensitivity Function
Our answer to the first question is that we pick endpoints based on sensitivity functions. Our candidate sensitivity functions are listed at the left-hand side. To test the performance of each sensitivity function, we vary the number of endpoints to be optimized based on different sensitivity functions and compare the area and power penalties of their fanin cone. As shown in the figures, sensitivity function five incurs the minimum area and power penalty. So we use sensitivity function five in our optimization. 

SLIDE: Iterative Optimization
For the second question, our optimization varies the number of optimized endpoints and we pick the minimum-energy solution. 
In our selective-endpoint optimization, we pick top K endpoints which have the minimum sensitivity. Then we perform timing optimization on the fanin cone of these endpoints. If the optimized endpoints have positive slacks with respect to the safety margin, we replace them with normal flip-flops. We then perform error rate estimation. We check the design energy. If the energy is reduced, we store the current solution. W then update the sensitivity functions and continue with the iteration. 

SLIDE: Clock Skew Optimization
Now I will discuss another optimization in our flow – the clock skew optimization. We use clock skew optimization to increas timing slacks on timing-critical and/or frequently-exercised paths. In the optimization, we first generate a sequential graph, in which each vertex is an endpoint and each edge is a timing path. The bottom figure shows one example. The weight of a path p-q is calculated based on this equation, in which slack p-q is the worst setup slcak of path p-q. Beta is a weighting factor; TG(p,q) is the toggle rate of path p-q. 
Then we find the cycle of paths with the minimum total weight, and adjust clock latencies on the cycle to evenly distribute the weights. After the optimization, we contract the cycle into one vertex. We iterately execute Step 2 until all endpoints are optimized. 
SLIDE: Methodology Comparison
This slide shows the optimization results with different methodologies. We compare our proposed methodology to two reference flows – the conventional methodology with only margin insertion; and a brute-force method which only use error-tolerant flip-flops for timing-critical paths. 
As we can see in the results, our proposed flow achieves up to 21% energy reduction as compared to the reference flows. In addition, the small-, medium- and large-margin indicate cases with 1-sigma, 2-sigma and 3-sigma SS corners. We can see that using our proposed method, the resilience benefits increase with process variation.  

SLIDE: Energy Reduction from AVS
We further perform the comparison at adaptive voltage scaling context. Since resilient design can detect timing errors, AVS allows a lower supply voltage for resilient designs to reduce power. Further, in the AVS context, our optimization is able to trade off timing-error penalty versus power reduction at a lower supply voltage. 
Figures show the experimental results. We can see that with AVS, our proposed flow achieves an average of 17% energy reduction as compared to the pure-margin designs. The results also indicate that the resilience benefits increase in the context of AVS strategy. 

We implement resilient designs with a margin of 25% of clock period inserted on the paths that have normal FFs as endpoints. We then scale supply voltages on the implemented designs (as shown in the figures) to find the minimum-energy point, but without causing timing violation at endpoints with normal FFs at the slow corner. 


SLIDE: Optimization of TIMBER-Based Designs
We also apply our optimization to TIMBER-based designs. Since TIMBER flip-flops use time borrowing to mask timing errors, additional constraints have to be addressed for the optimization. First, there must be no loop of TIMBER flip-flops. Second, there cannot be chained TIMBER flip-flops with more than two stages. Also, time borrowing requires additional timing slacks on fanout paths of TIMBER flip-flops. 
The figure shows our experimental result on ARM Cortex M0 at foundry 40nm technology. We assume an error detection interval of 10% of the clock period in this example. We observe that our optimization flow achieves 23% and 7% energy reduction compared to the pure-margin design and the brute-force method, respectively. 















SLIDE: Optimization for Mix-and-Match Die Stacking in 3DICs
Now I will describe our design-stage optimization for mix-and-match die stacking in 3DICs. 

SLIDE: Mix-and-Match Die Stacking
First, what is mix-and-match die stacking? It is an interesting idea proposed by previous works to stack slow dies with fast dies to improve the parametric yield in 3DICs. 
The figure shows one example. The numbers indicates die speed information measured before 3D integration. Based on the information, Ferri08 integrates slow CPU dies with fast L2 cache dies, and fast CPU dies with slow L2 cache dies. 

SLIDE: Design Stage Optimization for Mix-and-Match
This figure shows the timing slack improvement due to mix-and-match stacking. In the example, SS-SS indicates slow Tier 0 + slow Tier 1, SS-FF indicates slow Tier 0 + fast Tier 1. We can see that the mix-and-match stacking offers 75ps timing improvement over the conventional worst-case analysis. 

However, there is no holistic design for eventual stacking of 3DICs. In other words, no work considers the mix-and-match stacking during the design stage. 

The figure shows a simple example of how partitioning solution affects design signoff timing in the regime of mix-and-match stacking. In the example, with mix-and-match stacking, blue cut leads to the maximum timing slack, while red cut leads to the minimum timing slack. 

Therefore, our goal in this work is to study design-stage optimization for mix-and-match stacking. 

SLIDE: Challenges in Mix-and-Match-Aware Partitioning 
However, mix-and-match-aware partitioning is not trivial. 

First, the optimal cut location on one path can conflict with those on the other paths. The right figure shows one example that has different optimal partitioning solutions for different objectives. The first one optimizes the slack on path A-C. The second one optimizes the slack on path B-C. The third one optimizes the worst slack over two paths. And the fourth one optimizes the worst slack over two paths with large vertical interconnect delay impact. 

Second, partitioning is not free. There is delay impact of vertical interconnect insertion. 

Last, process variation can lead to asymmetric path delay distribution, which increases the difficulty for mix-and-match-aware partitioning. 

In the following slides, I will describe our proposed methodologies for mix-and-match-aware partitioning. 









SLIDE: ILP-Based Partitioning Method
We first propose an ILP-based partitioning method. The slide shows the formulation and notations. In the formulation, we minimize the maximum path delay. 
These two constraints force beta to be one if there is a cut between cell i and cell i’. 
This constraint calculate the path delay in the regime of mix-and-match stacking. dj and dj’ respectively indicate cell delay at process corner j and process corner j’. dVI is the delay impact of VI insertion. Last two constraints specify the area-balancing criterion.
 
Although the ILP-based method achieves near-optimal solution, it has large runtime. So we also propose a heuristic partitioning method.  

SLIDE: Heuristic Partitioning Method (1)
Our heuristic method has two steps. The first step performs maximum-cut partitioning on timing-critical sequential graph. 
We first classify the paths into three categories according to their slacks and the vertical interconnect delay impact. 
Type-I is the timing non-critical paths, which we do not optimize. 
Type-II is the timing-critical path without tolerance of VI insertion, of which the impact of VI insertion is larger than the timing benefits from mix-and-match stacking. We want to force the startpoint and endpoint of such paths to be on the same tier.  
Type-III is the timing-critical paths with tolerance of VI insertion. We want to force the startpoint and endpoint of such paths to be on different tiers.

In step 2, we extract the restricted sequential graph that contains only Type-II and Type-III paths. 
We then collapse vertices connected with Type-II paths into one vertex. 
On the updated graph, we perform maximum cut to partition the flip-flops into two tiers. 

SLIDE: Heuristic Partitioning Method (2)
In the second step of our heuristic we perform timing-aware multi-phase FM partitioning. 

One issue for the FM partitioning is that it is hard to foresee slack benefits with the existence of VI delay impact. 
As shown in the figure, moving one cell across tiers degrades the slack by 70ps due to VI delay impact. But the following moves on its neighbor cells compensate the VI delay impact and achieve 50ps timing improvement. 

To resolve such issue, we propose to cluster cells with a given range of cluster size, so that the timing benefits can compensate the VI delay impact. 

The bottom figure shows our optimization flow. Based on an initial partitioning solution, we perform multi-thread optimization. Different threads cluster cells with different cluster sizes, followed by timing-aware FM optimizations. Then we pick the solution with the maximum slack as the input to the next phase. 

SLIDE: Calibration of Heuristic Partitioning
We calibrate our heuristic partitioning method by compare its solution to that of ILP-based method. We perform such comparison with different VI delay impact, process corners. We observe that the heuristic method leads to only less than 30ps slack different compared to the ILP-based partitioning solution. 

SLIDE: Validation of Our Method
We also extend two existing 3DIC implementation flow with our partitioning method for mix-and-match. We observe from the results that our optimization achieves up to 16% performance improvement in the regime of mix-and-match compared to the existing flows. 
One of our future works is to combine stacking optimization and design-stage optimization for mix-and-match stacking. 

SLIDE: Roadmap of My Thesis
This slide shows the overview of the roadmap of my thesis. I am planning to have three parts – the mixed-fabric optimization, low-power optimization and multi-corner optimization. The current and target scopes are shown. 

SLIDE: Thank You!
Thank you again. 
SLIDE 1: TITLE
Good morning everyone. My talk is on “New Applications of Learning-Based Modeling in Nanoscale Integrated-Circuit Design”. 
SLIDE 2: OUTLINE
My talk is structured into three parts. In Part 1, I discuss two works related to improved accuracy of electrical modeling. The first work is about prediction of skews and latencies in on-chip clock distribution networks. The second work is on a methodology to proliferate golden signoff timing. 
In Part 2, I describe two works related to productivity improvement through improved design and implementation-space exploration. The first work is about area and power estimation of networks-on-chip or NoC routers to enable efficient architecture-level DSE. I describe parametric modeling and metamodeling approaches that we have used in this work. The second work is on prediction of power benefits of 3D-IC implementations relative to 2D-IC implementations. 
In Part 3, I describe one work to enable auxiliary physical design optimizations through modeling of complex black-box heuristics in commercial design tools. The work is on a new optimization to minimize clock skew variation across PVT corners with accurate models of post-routing signal. 
SLIDE 3: LIST OF PUBLICATIONS
Here is a list of all my publications that have either been accepted or are under review. The publications used in Part 1 are in blue, the ones in Part 2 are in brown and the ones in Part 3 are in violet. 
SLIDE 4: MOTIVATION: VALUE SCALING GAP
As part of our groups work on roadmapping of ITRS system drivers, we observe that lithography has continued to deliver “available” Moore’s Law scaling of transistor density growing at 2x/node. However, the “realized density” scaling has slowed down to 1.6x/node roughly around 2009. The picture on the top-right shows this gap which we at UCSD refer to as the “design capability gap”. Designers spend area, power and performance resources on reliability, variability, etc. for nanoscale IC design technologies. 
The picture below shows how resources spent on guardbands lead to lost benefits in performance, power, etc. In this work, we develop a chain of models to reduce these large guardbands by enabling incremental PD optimizations. 
SLIDE 5: MOTIVATION: HIGH COSTS, TURNAROUND TIMES
What prevents design- and implementation-space exploration today?
This figure shows that EDA tool license costs are very high. The design cost of a SOC consumer portable chip in 2013 is $45M. Further, there are no systematic methodologies to enable designers to perform DSE or ISE. To perform DSE with EDA tools implies long runtimes and the exploration is a highly iterative process.  In this work, we develop a chain of models that enable fast and accurate DSE, ISE. 
SLIDE 6: OUTLINE
I present the first work related to improved accuracy of electrical modeling, parts of which were published in DATE-2013 and SLIP-2013. 
SLIDE 7: CHALLENGE: HIGH DIMENSIONALITY
Why is Clock Tree Synthesis or CTS prediction hard?
Because a wide range of styles and methodologies are used to synthesize clock trees. The figure shows a clock tree cartoon where the yellow triangles are the clock buffers and the green rectangles are the sinks.  Inputs to synthesize a clock tree are testcases, layout contexts, tools and their knobs.
Testcases are described in Verilog RTL. They differ as designs use heterogeneous blocks and multiple clock domains, hard macros. There can be multiple layout contexts e.g., core area, aspect ratio, clock entry points. Tool flows may be different and there are multiple settings for each tool. Often design teams do not completely understand the “field of use” of a CTS tool. They tend use tools as a black box.  A testcase, layout context, tool and tool knobs are called a CTS instance.  Clock trees can be evaluated using multiple metrics such as power, skew, delay or latency and wirelength. 
Therefore, CTS prediction is difficult due to inherent high dimensionality.
SLIDE 8: OUR CTS TESTCASE: EXAMPLE
Previous works such as Tsay90 propose CTS testcases r1 to r5 with sink x, y coordinates. These have been widely used until the ISPD 2010 CTS contest benchmarks.  These benchmarks use a placement blockage and inverters/buffers in the tree. However, these works do not use realistic CTS instances to predict outcomes. 
This schematic shows an example of our CTS testcase. It has six sink groups K1 to K6. It uses real-world clock tree structures such as Clock-gating cells or CGCs; Clock dividers; and Glitch-free clock MUX. We also use multiple levels in the hierarchy. For example, sink groups K2 and K6 are at different levels in the clock tree hierarchy. 
In addition, we can change layout contexts in our testcases, e.g., core aspect ratio, placement and routing blockage, uniform and nonuniform placement sinks and multiple clock entry points. These kinds of instances can lead to accurate models for prediction.
SLIDE 9: MODELING PARAMETERS
Modeling parameters are important for accurate prediction. To describe a CTS instance, we use parameters to describe the microarchitecture, for example, the number of sinks, 
The floorplan context, for example, core area, core aspect ratio, clock entry point, placement and routing blockage as a percentage of the core area, tool constraints, for example, maximum skew, delay, buffer and sink transition time, maximum fanout, buffer size and wire width. We also use a parameter to measure nonuniformity in sink placement.
SLIDE 10: MODELING FLOW
In our flow, we use Verilog RTL testcases, synthesize them using Synopsys DesignCompiler to obtain a gate-level netlist. We use floorplan and microarchitecture parameters to generate a placed DEF file. Then, we use this DEF file, tool and the nonuniformity parameters to construct a CTS instance.
Now we use two CTS tools to synthesize clock trees from the CTS instance, and extract all CTS metrics of interest. Last, we use metamodeling techniques to derive fitted models for metrics.
Metamodeling techniques derive surrogate models from actual post-CTS data. The techniques we use are HSM, MARS, RBF and KG. Previous works demonstrate that these techniques are very accurate.
SLIDE 11: MULTICOLLINEARITY
The generic modeling problem is described by this equation. We estimate y hat x with a regression function of parameters x and regression coefficients beta, plus a random noise. The regression function is expressed as an offset plus the sum of regression coefficients times a function of each input parameter xi. 
If input parameters are linear combinations of each other, for example, aspect ratio, buffer and sink transition time and wire width, then the matrix of input parameters is ill-conditioned. It results in large variance in the regression coefficients and the relationship between the inputs and the actual response y of x become hard to determine.
Therefore, we get a bad model which results in large differences between the predicted and the actual outcomes. This is the reason, previous works e.g., C4 report large estimation errors as D is greater than or equal to 10.
SLIDE 12: OUR SOLUTION: HHSM
To cure these errors, we propose hierarchical hybrid surrogate modeling, HHSM.
HHSM is a divide-and-conquer approach. We divide the parameters into two sets. One set of k parameters has low collinearity whereas the other set may have high collinearity. We use variance inflation factor or VIF to determine low and high collinearity. When VIF < 5, parameters exhibit low collinearity. 
We derive hybrid surrogate modeling or HSM surrogate models described in C4 for each set and combine these models using weights determined from least-squares regression.
Formally, the model is given by this equation. W1 is the weight for the set with k parameters and w2 is the weight for the set with D-k parameters.

SLIDE 13: HHSM ACCURACY
This plot compares skew, delay or latency, power and wirelength estimation errors between HSM and our HHSM models with D varying from eight to 13. HHSM achieves up to 4x reduction in estimation errors compared to HSM.
As D varies from eight to 13, the HHSM estimation errors vary by less than 2%. The worst-case error is less than or equal to 13%.
SLIDE 14: USE MODEL 1: WHICH TOOL SHOULD BE USED?
We develop methodologies using HHSM for three use models to answer questions that physical design engineers typically ask (i) Which tool should be used? (ii) How should the tool be driven, that is, the field of use? And (iii) How wrong can the model guidance be? 
To answer which tool should be used, we develop the following methodology. Determine the best tool using HHSM models for a given tuple of input parameters, and compare with actual post-CTS data. If the better tools match, then the prediction is correct. 
The table quantifies accuracy of this methodology.  As D grows from eight, errors increase across all metrics. When D is greater than or equal to 12, the errors saturate. The worst-case error is 6.13%.
SLIDE 15: USE MODEL 2: HOW WRONG CAN THE GUIDANCE BE?
Model guidance is wrong when model predicts ToolA is better than ToolB but actual data shows otherwise. When guidance is wrong, we quantify the suboptimality using this equation.  Ratio of difference in CTS outcomes between tools to the outcome of the better tool, expressed as a percentage.
This table shows how often the guidance is wrong under the MODEL column and the percentage suboptimality under the SUB column. The worst-case suboptimality is less than 10%. 
SLIDE 16: SUMMARY
In this work, we study high-dimensional CTS prediction with appropriate modeling parameters. We generate realistic testcases with real world CTS structures. We propose HHSM to cure multicollinearity and report worst-case estimation error less than 13%. We develop methodologies for practical use models.
SLIDE 17: OUTLINE
The second work in Part 1 is about a methodology to proliferate golden signoff timing published in DATE-2014 and partially in SLIP-2013. 
SLIDE 18: MOTIVATION: DISCREPANCY IN PATH SLACK
In any IC design flow, timing closure is a critical signoff step. There are many commercial timing signoff tools. This plot here compares path slacks from two signoff tools T1 and T2 in the X and Y axes respectively. 
The netlist, SPEF and library inputs to these tools are identical. BUT, the slacks estimated by the tools diverge from the perfect correlation line. Slack can diverge by up to 110ps. For modern processors, this means around 20% difference in performance, that is, a difference of one technology node of Moore’s Law scaling.
SLIDE 19: CHALLENGES IN TIMING SIGNOFF
So, what can be challenges in timing signoff for design teams?
Multiple commercial tools exist and they have high license fees.
Complexities of tools grow with each release. Tools contain millions of lines of complex black-box code; tools diverge from published documentation, and use proprietary timing engines. Therefore, the correlation problem is seemingly unbounded as the space of possible timing paths, slew times, etc. is essentially infinite.
Cost and budget constraints prevent design teams from owning licenses of multiple tools. Two usage models are possible. First, to understand if they have overdesigned or underdesigned. Second, how far their implementation is from signoff at each optimization loop. 
We develop the learning-based GTX tool to correlate timing signoff between tools. 
SLIDE 20: MODELING ELEMENTS OF GTX TOOL
Our analysis shows that path slack differs due to discrepancies in cell, wire and stage delays. Path slack is calculated from the required setup time at the capture flip-flop of the path and from stage delays; these in turn are calculated from cell and wire delays in each stage.

We model setup time of launch flip-flops. Next, we model cell delay for each pin-to-pin arch of all cell types in a design by varying input slews and loads. We model wire delay by varying R, C and input slews. We use estimates of wire and cell delay models to model stage delay. Finally, we use estimates from all these models to model path slack. 
Because of the layered modeling structure, we say that our method is “deep”.  We do not combine individual models in an additive manner as it can result in errors being added up.

SLIDE 21: MODELING FLOW
Our flow works as follows. We train models using timing data obtained from artificial testcases.  We validate the models using data from artificial as well as real designs to minimize both mean-square error and range of errors. We test the models using real designs. The flow bounded by the blue dotted box is a one-time effort.
A new design taped out in the technology can use cells and/or wiring configurations that are out of scope for the current fitted models. Such “new” cells/wires can introduce divergence in timing reports. We use data from new designs to test the existing models.  If the error is above a threshold, we use datapoints from the new design to refine our models. We refer to this flow as “incremental modeling” as shown by the red-dotted box.

SLIDE 22: EXPERIMENTAL SETUP AND TESTCASES
Our design of experiments includes two foundry technology libraries and netlist, SPEF and SDC files from post-SP&R implementation. 
We use real designs, such as leon3, as well as artificial testcases. Artificial testcases allow us fine-grained control of pin-to-pin arcs, input slews and loads. We use several modern machine learning techniques including artificial neural network and random forests, and use large-sized datasets of over 100K datapoints for training and testing. 
SLIDE 23: CORRELATING TWO SIGNOFF TOOLS
This plot shows the range of errors in the Y-axis and timing in the X-axis. Original is the difference in timing between two tools and GTX is the result of estimating one tool’s timing using timing data from the other tool. 
GTX reduces slack divergence from 89ps to 22ps, that is, up to 4 times. Reduction in slack divergence is a result of reduction in stage delay divergence by 5X, cell delay divergence by 8X and wire delay divergence by 9X.
SLIDE 24: PATH SLACK FROM TIMNING REPORTS
Here is a snippet of timing reports between two tools T1 and T2. GTX estimates timing report of T1 using reports from T2. GTX estimates of T1’s reports are shown in red and the actual report from T1 is shown in green. 
Delay divergence reduces from 39ps to 0.5ps and slack divergence reduces from 249ps to 3ps.
SLIDE 25: CORRELATING SIGNOFF AND DESIGN TOOLS
GTX can also correlate timing between a signoff and a design implementation tool. This plot compares difference in original and GTX estimates of a leading signoff and a leading design implementation tool. The range in errors is show in the Y-axes and timing in the X-axis.
Again, GTX reduces slack divergence by 7X, from 163ps to 23ps.
SLIDE 26: SUMMARY AND PROPOSED RESEARCH
Timing correlation with multiple tools can help design teams fix overdesign or underdesign. Commercial signoff tools’ reports diverge significantly. We develop GTX and predictive models to reduce timing divergence by up to 6.6X. We validate GTX across multiple design, libraries and analysis modes. 
Our ongoing works are to expand GTX to use CCS timing models and develop methodologies to integrate GTX into timing closure flows. 
SLIDE 27: OUTLINE
Moving on to Part 2, I discuss parametric and metamodeling methodologies that we have developed to estimate area and power of NoC routers. This work was published in DAC-2012 and was nominated for the best paper award. 
SLIDE 28: NOC MODELING INACCURACIES SO FAR …
Networks-on-Chip have proved to be highly scalable interconnect fabrics for many-core processor architectures and ORION is widely used tool to estimate power and area of NoCs. The picture here is of a simple wormhole router showing the router components such buffers, crossbar and the arbiter.    ORION1.0 released in 2002 and ORION2.0 released in 2009 use circuit or logic templates to model each component block of the router. 

So, what is the problem with modeling based on circuit templates? 
First, there can be RTL code mismatch. For example, there may be an additional pipeline register used in the RTL. Second, when the RTL is synthesized, logic transformation and technology mapping significantly change the gates. For example, a bunch of NOR gates may get replaced by AND-OR-INVERT. 
Furthermore, ORION2.0 does not model control logic and the templates miss implementation such as PVT corners, layout contexts, etc. These make the ORION2.0 models inaccurate when compared with actual implementation data. 

This figure plots the number of instances from netlists of XBAR synthesized router RTLs – Netmaker from Cambridge and Stanford NoC and ORION2.0 in the Y-axis and the number of ports in the X-axis. As the number of ports grows, ORION2.0’s overestimation error grows to 460% at P = 10.  

SLIDE 29: PARAMETRIC MODEL DEVELOPMENT

Here is our modeling flow to develop parametric models. We use two router RTL generators, Netmaker and the Stanford NoC, a range of microarchitectural parameters such as number of ports, VCs and buffers and the flit width and a range implementation parameter such as the clock frequency as input.  We hierarchically synthesize, place and route using multiple commercial tools - Synopsys DC and Cadence RC for synthesis and Cadence SOC Encounter for place and route. We analyze the post-synthesis netlists and develop the ORION_NEW models.

There are two approaches to estimate power and area using the new models. The first, manual approach is used to estimate gate count of each component block. Then we use information such as cell area, leakage, pin capacitances and internal energy from the technology libraries to estimate area and leakage, switching and internal power using the gate counts.

As evident, the manual approach is quick and easy and can be used for pathfinding when technology libraries are unavailable; however, fine-grained implementation details such as routed wire length and area, and power of setup buffers, etc. are missing. 

The second, least-squares regression fit approach uses post-P&R standard-cell count, area, leakage, switching and internal power to estimate gate count, area and power. The LSQR approach is accurate because it captures fine-grained implementation details, but is time-consuming as it requires generating training sets obtained by simulating the post-P&R flow several times. 

SLIDE 30: RESULTS OF PARAMETRIC MODELING: NOC POWER
In this plot, the ORION2.0 estimation errors of power are circled. Using our methodology, the average error for both Stanford and Netmaker routers are less than 5% and maximum error is less than 38% at 45nm as well as 65nm. The worst-case error reduction is up to 6.5x. 
SLIDE 31: RESULTS OF PARAMETRIC MODELING: NOC AREA
Similarly, in area estimation, ORION2.0 has very large errors as highlighted by the circles. Our methodology reduces the average estimation error to less than 10% and maximum errors to less than 30%. Reduction of maximum errors is valuable for designers and architects as they care about minimizing the worst-case errors. The worst-case error reduction is up to 4x.
SLIDE 32: METAMODELING WITH POST-P&R DATA
We develop another methodology to estimate NoC area and power by using metamodeling. Similar to the parametric modeling methodology, we obtain post-P&R area and power reports by varying architectural, implementation and operational parameters. We apply metamodeling techniques such as KG, RBF, MARS and SVM and develop area and power models. 
Compared to the parametric modeling methodology, metamodeling is fast because we do not need to develop the parametric models from post-synthesis data. 
SLIDE 33: METAMODELING VALIDATION AND RESULTS
We generate a total of 256 data points and use two sizes of training and testing sets. The first set is “sparse and restricted”. It contains only 50 data points and omits higher values of microarchitectural parameters. For example, it does not include values of buffer sizes greater than seven. The second set is sparse only and contains 64 data points that are uniformly sampled using Latin Hypercube sampling. 
The plots show area and power results at 45nm and 65nm. RBF performs the best with the maximum error being around 20% at 65nm for area and at 45nm for power. 
SLIDE 34: SUMMARY AND PROPOSED RESEARCH
We develop new modeling methodologies for NoC routers that relax the template mindset. The models capture architecture, implementation and operation-level details. 
Using the proposed methodologies, we reduce worst-case estimation errors by factors of up to 6.5X as compared to ORION2.0
We released ORION3.0 software on the web in Feb-2013 and it implements our parametric and metamodeling methodologies. There have been over 380 downloads since Feb-2013 and only one bug has been reported so far in Oct-2013. 
Our ongoing studies include trace-level power simulation and estimation using metamodeling and to develop a delta power modeling based on post-synthesis netlists and models of switching power and buffer internal power.
SLIDE 35: OUTLINE
The second work in Part 2 is about prediction of 3D-IC power benefits relative to 2D-IC implementations. This is a joint work with Qualcomm Research and has been submitted to DAC-2015. 
SLIDE 36: MOTIVATION: QUANTIFY 3D BENEFITS
To regain performance and power benefits lost due to guardbands in 2D implementations, 3D-ICs have emerged as a promising solution. However, power estimation of 3D implementations is challenging because 3D benefit varies with netlist topologies, constraints and implementation styles. Also, there is no “golden” 3D implementation flow. 
To the best of our knowledge, no tool/model exists today that can predict 3D power benefits based on netlists, constraints and 2D implementations. 
SLIDE 37: IMPROVEMENTS TO THE LATEST 3D FLOW (FROM GT)
To develop an accurate estimation tool, we need a reliable 3D flow. We obtain the latest academic 3D flow from Georgia Tech and have improved it in several ways. These include automatic handling of multiple aspect ratios, pin placement that is aspect ratio and perimeter-aware, usage of 28nm FDSOI SRAMs and an automated flow to sweep multiple key implementation parameters. 


SLIDE 38: 3D POWER ESTIMATOR
We develop separate models for internal, switching and leakage power components. We then combine these models to estimate total power. We use artificial neural networks to develop the models and inject sensitivity at the synthesis and P&R stages in the form on WLM and table-based cap scaling. 
We estimate % delta power as it can lead to more accurate estimates of actual power. For example, 10% error on actual would imply the estimate is anywhere between 72mW and 88mW. However, 10% error on the %delta means the estimate is between 79mW and 81mW. 
SLIDE 39: MODELING PARAMETERS
Our modeling parameters include total power and cell area from synthesis with WLM cap scaling. From 2D P&R, we use max transition, max fanout, clock period, utilization, aspect ratio, PVT corners, % of memory area, internal, switching and leakage power values, wirelength and the number of buffers and inverters. 
Based on our analysis, we omit some constraints and implementation parameters because they do not correlate with delta 3D power relative to 2D. 
SLIDE 40: RESULTS OF 3DPE
We use five classes of testcases as shown in the table here. The instance count, %buffers and %sequential cells vary widely across these testcases. The CPU and GPU testcases also use SRAM. These testcases enable us to make our models generalizable. 
The plots at the bottom show that we achieve highly accurate predictions with around 0.1% of average and around 10% of max-min errors. 
SLIDE 41: NEW MODEL VALIDATION: STRESS-TESTING
We use a novel validation method to stress-test our models. We vary the input parameters over wide ranges of values and test if the model estimations are sensible for realizable netlists. Among 434 testcases, 3DPE estimates up 39% less power in 3D relative to 2D. The bottom-left plot shows that in certain cases the benefit may be ~120%, but these netlists are not physically realizable. 
SLIDE 42: MGI: MODEL-GUIDED IMPLEMENTATION METHODOLOGIES
We demonstrate the usefulness of 3DPE in guiding designers to achieve the maximum 3D benefit. In this experiment, the goal is to determine the WLM scaling that leads to minimum 3D power. The plot shows that the default WLM cap of 1.00pF does not deliver the minimum 3D power. A value of 0.45pF is the best scaling; our model predicts a value of 0.75pF, but the suboptimality is 0.34mW or 1.62%. 3DPE can guide designers to achieve ~5% less power. 


SLIDE 43: MGI: MODEL-GUIDED IMPLEMENTATION METHODOLOGIES
Another use model of 3DPE is to predict % delta power saving in 3D for high-utilization implementations. High-utilization implementations provide more 3D benefits but have large runtimes. However, low-utilization implementations have small runtimes but provide small 3D benefits. The table shows that 3DPE can guide designers to choose a value of utilization, aspect ratio and clock period tuple that provides the best 3D benefits. In the actual data the range of benefits is between 1.58% and 2.88%. 
SLIDE 44: SUMMARY AND PROPOSED RESEARCH
In this work, we have extended the latest 3D flow so as to generate training data to develop an accurate 3D power benefits estimator. We develop a novel validation method to stress-test the models and demonstrate application of 3DPE in model-guided implementations. 
Our ongoing works include extending 3DPE from the block-level to full SOC-level. A key challenge is to identify the right parameters as the problem becomes high-dimensional. 
SLIDE 45: OUTLINE
In Part 3, I present one work on model-guided incremental optimization to minimize the sum of clock skew variation across PVT corners. This is a joint work with Samsung and has been submitted to DAC-2015. 
SLIDE 46: CHALLENGE: “PING-PONG” EFFECT OF MULTI-CORNER TIMING OPTIMIZATIONS
Modern SOCs implement features such as DVFS, etc. to achieve power, performance requirements. These features require designs to be signed off at multiple PVT corners. Fixing timing violations become challenging as fixes at one corner can lead to new violations at another corner, thereby a “ping-pong” effect. Minimizing clock skew variation is a strong knob to fix this “ping-pong” effect because only datapath fixes are not very effective when the clockpaths have large variations.  
Therefore, we minimize the sum clock skew variations across PVT corners. This implicitly minimizes the overall physical implementation costs. 
SLIDE 47: EXAMPLES OF (LOCAL) OPTIMIZATION MOVES
We perform both global and local optimizations on the clock tree. As part of our local optimization we implement three types of moves. Here is an initial subtree. In Type-I move, we size and/or displace a buffer. In Type-II move, we displace the buffer and/or size one of its child nodes. In Type-III move, we change the parent of a node, that is, reassign a driver.  
SLIDE 48: OPTIMIZATION FLOW
The figure shows our complete optimization flow and the yellow highlighted box shows the local optimization in which we use learning-based delta latency models to guide the optimization. After each move, we construct a new tree to mimic the actual tool routing and recalculate slew and delay of upstream parent node and two-levels of downstream children nodes Interpolated delay, slew using classical methods (Elmore delay, D2M, PERI) do not match those of golden timer’s analysis. The estimated routing pattern and wire delay can have discrepancy with respect to the actual ECO solution of a commercial router. 
SLIDE 49: TESTCASES, DESIGN OF EXPERIMENTS
We create artificial testcases that resemble clock trees in SOC blocks and vary multiple parameters to generate our training data. We develop large testcases that resemble high-speed CPU blocks and memory controllers in SOCs to test our models and our optimization flow. The bottom figures show examples of floorplans and clock trees of two testcases.
SLIDE 50: MODEL EVALUATION
These plots show the performance of our delta latency model at the nominal PVT corner. The parameters we use to develop the model are the delta of Elmore delay for a FLUTE RSMT, Elmore delay for a STST relative to the initial tree, the delta of the bounding box area relative to the initial tree, the ratio of bbox aspect ratio and fanout after and before a move. We achieve a R-squared value of 0.975 and the maximum of the absolute errors are ~20%. 
SLIDE 51: RESULTS OF MODEL-GUIDED LOCAL OPTIMIZATION
These plots present the results of our model-guided local optimization. The blue dots correspond to Type-I, red dots to Type-II and green dots to Type-III moves. As compared to random moves, our model-guided optimization achieves 15ns of sum of clock skew variation reduction. Overall, we reduce the sum of clock skew variations by up to 4.5% for the CLS2v1 testcase. 
SLIDE 52: SUMMARY AND PROPOSED RESEARCH
In this work, we develop a novel framework to minimize the sum of clock skew variations across PVT corners. We use learning-based delta latency models which guide the local optimization to achieve up to 4.5% reduction in sum of clock skew variations. 
Our ongoing work includes development of models to predict a buffer location for minimum skew over a continuous range of possible buffer locations and investigation of whether a worse initial start point can enable us to achieve larger skew variation reduction across corners. 
SLIDE 53: ADDITIONAL ONGOING RESEARCH
We are also pursuing additional research with the IT teams at Qualcomm San Diego and India on two problems. The first is about resource usage prediction for physical design jobs so as to reduce wastage, which is in the order of 40X currently. Our first goal is to predict the average memory required to run a PD job to within an accuracy goal of 10%. 
The second problem is to schedule resources per activity within a project in a multi-project and multi-resource scenario. IT teams within IC design companies must constantly evaluate ways to minimize cost to purchase new resources without significantly impacting project tapeout schedules. We have developed an initial MILP-based formulation with multiple penalty functions for project makespan as well as resource usage per project. The models will provide the upper bounds on resources which are the inputs to the optimization. 
Now, I conclude my talk. Thank you for your attention. 
SLIDE 1: TITLE
Good morning everyone. My talk is on “New Applications of Learning-Based Modeling in Nanoscale Integrated-Circuit Design”. 
SLIDE 2: OUTLINE
My talk is structured into three thrusts.  Thrust 1 presents three new works on design productivity gains through improved design- and implementation-space exploration.
Thrust 2 presents one new work on improved accuracy of electrical modeling. Thrust 3 presents three new works to optimize design power, energy, project management, and cost. 
Thrusts 1 and 2 are related to learning-based modeling, whereas Thrust 3 changes the envelope of what is being modeled  or predicted.
SLIDE 3: PD PICTURE
Works presented in each thrust can be placed in various parts of IC design flow figure. The two works listed on top apply to system-level optimization and scheduling of design infrastructure. Majority of the works are in the area of physical design that include floorplanning, placement, Clock tree synthesis and routing. 
SLIDE 4: RECAP OF UQE
Works presented at UQE can be placed under each thrust as follows. 
SLIDE 5: TODO’S FROM UQE
Out of the TODO’s from UQE, three are done and two are not done due to changed research directions. These include prediction of embedded memory timing failures at floorplan stage, “true 3D” placement, prediction of routability and #metal layers, and reliability-constrained multi-core task scheduling.  
SLIDE 6: NEW AFTER UQE
New works after UQE are highlighted in blue and are the focus of today’s talk. 
SLIDE 7: PREDICTION AND OPTIMIZATION CONNECTION
Even though Thrust 3 has no learning-based modeling, yet it is connected to the topic and other two thrusts due to two reasons. 
Better prediction leads to more accurate constraints, e.g., upper bounds or requirements, during optimization. Thus, our optimization solutions are better. For example, using past project requirements, we can create a model to predict storage upper bounds. Using requirements from new project, we estimate the current upper bounds and then optimize schedule and resource allocation. Clearly, if the upper bounds are incorrect, the optimization solutions will be incorrect.
Better optimization also leads to better flows, for example, and changes the envelope of what is being predicted or modeled. For example, an optimized 3D flow enables us to obtain accurate ground truth and realistic models. 
SLIDE 8: PRELIMINARIES: Terminologies
This slide shows preliminaries that define some IC-design related terminologies used in the rest of this talk. These include design space, implementation space, IC blocks, commercial EDA tool examples, and design infrastructure. I also provide definitions of other jargons in the handout.
SLIDE 9: LIST OF PUBLICATIONS (USED IN THESIS)
Here is a list of publications used in the thesis. The ones in blue are used in Thrust 1, ones in brown are used in Thrust 2 and the ones in green are used in Thrust 3. Full list of all my used and unused publications are in my webpage.
SLIDE 10: MOTIVATION: VALUE SCALING GAP
As part of our groups work on roadmapping effort for International Technology Roadmap for Semiconductors or ITRS, we observe that lithography has continued to deliver “available” Moore’s Law scaling of transistor density growing at 2x/node. However, the “realized density” scaling has slowed down to 1.6x/node roughly around 2009. The picture on the top-right shows this gap which we at UCSD refer to as the “design capability gap”. 
Overall, there is slowdown of power-performance-area-cost (PPAC) from process and device scaling. Designers spend area, power and performance resources on reliability, variability, etc. for nanoscale IC design technologies. So, even 10% or 20% improvement in PPAC is a huge deal. 
The picture below shows how resources spent on guardbands lead to lost benefits in performance, power, etc. In this work, we develop a chain of models to reduce these large guardbands by enabling incremental PD optimizations. 
SLIDE 11: MOTIVATION: HIGH COSTS, TURNAROUND TIMES
What prevents design- and implementation-space exploration today?
This figure shows that EDA tool license costs are very high. The design cost of a SOC consumer portable chip in 2013 is $45M. Further, there are no systematic methodologies to enable designers to perform DSE or ISE. To perform DSE with EDA tools implies long runtimes and the exploration is a highly iterative process.  In this work, we develop a chain of models that enable fast and accurate DSE, ISE. 
SLIDE 12: OUTLINE
In Thrust 1, I present the first work related to early-stage slack prediction of embedded memories. This work has been presented in ASP-DAC 2016.  

SLIDE 13: KEY TAKEAWAYS
Timing closure is time-consuming and complex at advanced nodes as it increases turnaround time. Early prediction  of slack can reduce design cost and turnaround time. This problem is difficult because floorplanning with SRAMs is complicated due to congestion, power delivery etc. Also, Multiphysics effects make the problem harder. We describe a novel learning-based methodology to address this problem. 
SLIDE 14: TIMING PRELIMINARIES
Before I describe the prediction problem and our solution, I will provide background terminologies. 
This slide shows timing preliminaries. Setup time is the time for the data to stabilize before the clock edge. Transition or slew time is the time a rising signal takes to transition from 10% voltage to 90% voltage.  Load is the sum of pin and wire capacitances. Gate or cell delay is the propagation delay through standard cell input pin to output pin. 
SLIDE 15: PATH SLACK PRELIMINARIES
Arrival time is the time signal takes to travel from clock pin of launch flip-flop to D-pin of capture flip-flop. It depends on cell and wire delays in the path. Required time is the clock period minus the setup time. Slack is the difference between required and arrival times. In this figure the critical path is shown in grey. 
SLIDE 16: SOC FLOORPLAN
Floorplan is an arrangement of various blocks in a SoC – processor cores, GPU cores, caches, etc. The left figure is the floorplan of Apple A6 found in iPhone 5. It is fabricated in 32nm and has a die size of 97 mm2. The right figure is the floorplan of Apple A7. It is fabricated in 28nm and the die size is 102 mm2. 
SLIDE 17: CHALLENGE: SENSITIVITY OF SLACK TP SPACING BETWEEN MEMORIES
Now that I have explained background, I go to the problem of early-stage prediction of timing slack of embedded memories. I discuss two modeling challenges for this problem. 
Our experimental results show that the spacing between memories affects post-P&R and multiphysics slack values. The figure in the bottom-left shows our design with five SRAMs placed in the top-left corner of the placement region. The other corners contain other placement and routing blockages; hence standard cells can only be placed in the cross-shaped region in the center of the block. We vary the spacing between SRAMs, that is, the space between these blue-striped boxes in steps of 10 micron from 10 micron to 30 micron. 
The slack difference between SRAMs can be larger than 300ps as shown in the bottom-right plot. This is due to congestion and buffer placement. Hence, slack values vary in non-obvious and/or noisy manner when the spacing is changed.
SLIDE 18: CHALLENGE: ABSTRACTION OF P&R STAGES AND TOOL NOISE
Another challenge is modeling must abstract multiple stages of the P&R flow as shown in the figure below. EDA tool noise is another factor our modeling must comprehend. As our goal is to predict post-P&R and multiphysics slack values at the floorplan stage, the modeling must therefore comprehend effects of placement to routing, extraction, STA, etc. 
Our goal is to derive an approximation function “f” that comprehends the combined effects of the netlist, constraints, P&R stages and tool noise. 
SLIDE 19: MULTIPLE PHYSICS: MAKES PROBLEM HARDER
We define multiphysics STA as performing STA with more than one physics such as IR, thermal, crosstalk, etc. 
Design teams can achieve more accurate timing results by closing multiphysics analysis loops. The figure here shows slack of two SRAMs. The deep blue bar on the left shows slack with no IR is positive 480ps on SRAM #1. By including static IR analysis, the light blue bar here shows that slack become positive 250ps, that is, more pessimistic. By including, dynamic IR analysis, the slack for the same SRAM becomes 20ps as shown by the blue-green bar on the left. We also demonstrate here that more than one dynamic IR loop, shown by the yellow, red and brown bars, can slightly reduce pessimism of only one loop of dynamic IR analysis by 25ps. This is because timing windows change. The key message here is, including more than one physics not only makes the timing analysis more accurate, but also more pessimistic. 
However, predicting multiphysics slack at early design stages is very challenging as shown in this plot. In the X-axis, we have 50 different implementations of the same design in which we vary the clock periods and transition time constraints. The red line shows SRAM slack without IR and the blue line shows SRAM slack with dynamic IR. Modeling such a non-uniform trend is difficult.
SLIDE 20: MULTIPHYSICS ANALYSIS FLOW
Here, I describe our multiphysics analysis flow. We have developed this flow with significant guidance from our industry colleagues. In this work, we consider only IR drop and crosstalk and perform these analysis using RedHawk and PrimeTime-SI tools, respectively. 
The inputs to PTSI are SDC, Verilog netlist, Liberty DBs, parasitic SPEF. PTSI generates a .timing file that contains timing windows of transition times of each pin in the netlist. The input to RedHawk consists of this .timing file from PTSI, Liberty .lib files, DEF, SPEF and technology files. RedHawk generates an IR drop report per instance in the netlist. 
We perform STA again using this IR drop map and go around this loop four times. It is possible to include other physics such as temperature and reliability, which we have not explored in this work.
SLIDE 21: FLOORPLANNING AND SRAM PLACEMENT
To explore which design parameters affect post-P&R and multiphysics slack, we conduct multiple experiments by varying the floorplan and power delivery network or PDN contexts. This figure shows how we have parameterized our floorplan and SRAM placement. The blue-striped boxes represent SRAMs, the blue box represents buffer screens and green boxes represent blockages that emulate other SRAMs.
We vary the core width and height, SRAM width, height and spacing, blockage width and height, width and height of the routing channels and buffer screen widths.
SLIDE 22: LIST OF PARAMETERS
Here is a complete list of our modeling parameters. The prefix “N” in the 1st column denotes a netlist-related parameter. The prefix “FP” denotes a floorplan-related parameter, and the prefix “C” denotes a constraint-related parameter. 
The netlist parameters are labeled from N1 through N7, the floorplan parameters are labeled from FP1 through FP11, and the constraints are labeled from C1 through C9. In total, we have 27 parameters.
SLIDE 23: MODELING TECHNIQUES AND FLOW
We extract our parameters from netlist, netlist sequential graph, floorplan context and constraints. We obtain ground truth from P&R and multiphysics STA reports. We normalize all our data points to within a range of 0 and 1, both inclusive. 
We use one linear – LASSO with L1 regularization and three nonlinear – SVM with RBF kernel, ANN with one input, one output and two hidden layers and Boosting with SVM as weak learners. 
We combine the predictions from each of these models using weights. We use a weighting strategy so that when actual negative slack values are predicted as positive in a data point, we retrain our model by increasing the weight for the data point by five times. 
We perform five-fold cross-validation during our training phase for each of the modeling techniques.
SLIDE 24: BOOSTING WITH SVM
We briefly describe our Boosting implementation with SVM with RBF kernel. This is a new implementation and our contribution.
We build a cascade of weak SVM learners. The learning is weak because we terminate the grid search of hyperparameter values when the predicted slack is within 20% of clock period. Without Boosting, we exit when the predicted slack is within 5% of the clock period.
 We adjust the weights at each stage based on the error observed for each data point. The newly weighted data point is an input to the next stage. As we cascade through the stages, errors become small.
We use 40 stages because our experimental results show that beyond 40 stages, there is no significant improvement in error. 
We combine the output of each stage using a linear regressor to determine the predicted outputs from Boosting. 
SLIDE 25: POST-P&R SLACK PREDICTION
I present results of post-P&R slack prediction here. We have a total of 2515 data points. We use 60% of these for training and validation, and the remaining 40% for testing.
This plot shows the effect of our weighting strategy for data points with negative slack values. We show the actual slack values in the X-axis and the error of slack prediction in the Y-axis. When the actual slack is less than -100ps, the error of slack prediction is always negative. 
These two plots show our modeling accuracy for post-P&R slack. In the left plot, actual slack is in the X-axis and predicted slack is in the Y-axis. The solid black line denotes perfect correlation. The right plot shows a histogram of error of slack prediction. The solid vertical yellow line denotes zero error. The worst-case error is 224ps and the average error is 4ps. Even though this is very early-stage prediction, the results are surprisingly accurate.
SLIDE 26: MULTIPHYSICS SLACK PREDICTION
These plots show the predicted versus actual multiphysics slack values. Recall that we perform multiphysics STA analysis using PTSI by annotating IR drop values for each cell from our RedHawk analysis. The worst-case and average errors are 253ps and 9ps, respectively. These values are larger than post-P&R predictions because predicting multiphysics slack is harder than predicting post-P&R slack.
SLIDE 27: MODELING FIDELITY
Here, we show the confusion matrix of our predictions of multiphysics slack on the test set. We report common classification metrics in ML literature, that is, false positives, false negatives, precision and recall. False negatives are 3% of the data points, that is, our model suggests a floorplan needs to be changed when it is actually not required. False positives are 4% of data points, that is, our model deems a floorplan to be good when it is actually bad and can lead to timing failures on SRAMs. 
For the data points with positive slack, our recall is 95% for 93% precision. For the data points with negative slack, our recall is 90% for 92.5% precision. We believe our model can provide guidance to designers with high fidelity. Even though this is very early-stage prediction, the results are surprisingly accurate.
SLIDE 28: SUMMARY
In conclusion, we note that early stage prediction of timing failure is important and timing closure with multiple analyses are important for complex SOCs for accuracy and faster design turnaround time. 
We present a machine learning-based methodology to predict post-P&R and multiphysics slack values within a worst-case error of 253ps.
SLIDE 29: OUTLINE
The second work in Thrust 1 predicts 3DIC benefit from 2DIC implementations and has been presented at DAC 2015. 
SLIDE 30: KEY TAKEAWAYS
3DICs continue Moore’s Law trajectory of value scaling and are fundamental to “More than Moore” idea. Power benefit is the key value proposition of 3D but no tool predicts 3D power benefits from 2D implementations. The problem is difficult because 3D benefits vary with netlist topologies, constraints; implementation space is high-dimensional; lack of a golden 3D flow and a chicken-and-egg loop of trying to embed netlists not created for 3D into 3D. A higher-level chicken-and-egg loop is until people are convinced about 3D benefit, no investment on 3D tool and flow developments will be made. Therefore, a benefit estimation tool is required. 
Our solution is to develop a novel learning-based 3D power estimation tool (3DPE) to address this gap. 

SLIDE 31: TOOL COMMANDS AND OPTIONS
I provide some background terminology now.
Commercial EDA tools provide a plethora of commands and options. Cadence Innovus is a P&R tool. For each physical design stage, the tool provides multiple commands. Synopsys Primetime is a signoff tool and version J-2014.12 has 448 commands. These tool knobs along with constraints make the implementation-space high-dimensional.
SLIDE 32: SHRUNK2D (S2D): OUR BASELINE 3D FLOW
This figure shows a classic 2DIC. The height and width of the die are H and W, respectively. When this implementation is changed to 3DIC, we can create two vertically stacked dies. The height and width of each die is divided by the square root of two with respect to those of the 2DIC. The dies are interconnected by vertical interconnects.
Shrunk2D is another way to emulate a 3DIC by doing P&R in a die with the same height and width of the 3DIC.  This flow proposed by Panth et al. at Georgia Tech and is the strongest academic “3D” flow today. 
SLIDE 33: “TRUE 3D” OBJECTIVE in APlace3D (A3D)
For years, our group and collaborators at Qualcomm used the S2D flow as a golden 3D implementation flow. Recently, the APlace implementation from 2004 timeframe and extended it to 3D by a postdoc in 2010. We revisited the implementation and submitted APLace3D (A3D) to ASPDAC-2017 with the postdoc as our co-author. A3D is interesting because it achieves significantly better QoR than S2D and provides opportunity for better predictions – of a 3D power estimation tool here and for routability in 3D that we will see in the next topic. 
APlace3D implements a true 3D objective. The figure shows cartoon of a two-tier 3DIC. The bottom tier is Tier 0 and top tier is Tier 1. We also show placement of 4 pins A, B, C, D of a net. Pins A and B are on Tier 0 and pins C and D are on Tier 1. 
Our true 3D objective is the weighted sum of half-perimeter wirelength or HPWL0 of the bounding box of pins A, B on Tier 0 and HPWL1 of the bounding box of pins C and D, both shown  in green color. The third term is the HPWL of the union of all 4 pins when the two tiers are overlapped. We call this the HPWLov. W1, W2, W3 are user-defined weights. We assume that no signal net crosses between two tiers more than once. This objective comprehends minimization of HPWL on each tier along with the HPWL when both tiers are overlapped. 
SLIDE 34: APLACE3D FLOW
Our APlace3D flow using commercial P&R and signoff tools is as follows. 
We place flip-flops, macros and PI/POs. We perform clock tree synthesis at this stage because we adopt the split at sink strategy proposed by Panth et al. We then invoke A3D to perform 2-tier placement of standard cells. We legalize the placement in a commercial tool. Next, we add VIs a dummy cells in the netlist and invoke A3D again to perform 3-tier placement. We fix the placement of standard cells on the top-most and bottom-most tiers and allow only VI cells to move in the middle tier. 
Next, we change the VI cells to PI/POs and place them on each tier. We then perform tier-by-tier legalization, routing and optimization in a commercial P&R tool. Finally, we perform timing and power signoff in a commercial signoff tool. 
SLIDE 35: COMPARISON OF 2D VS. A3D VARIANTS
We now present our results with the A3D flow. Here we compare 2D and the three variants of A3D, namely, Gordian-L in 3D (A3D-GL3D), weighted wirelength (A3D-WWL) and true 3D (A3D-T3D). 
This plot shows normalized WL wrt 2D in the y-axis in 28nm FDSOI. WL reductions are shown by these arrows and the numbers next to them. 
This plot shows normalized WL in 28nm LP. 
This plot shows normalized power in 28nm FDSOI and this plot shows normalized power in 28nm LP. 
Overall, we achieve up to 31% WL reduction and 20% power reduction compared to 2D.  
SLIDE 36: COMPARISON S2D VS. A3D VARIANTS
In this slide, we compare the strongest academic flow, S2D with the three variants of A3D. 
This plot shows normalized WL wrt 2D in the y-axis in 28nm LP. WL reductions are shown by these arrows and the numbers next to them. 
This plot shows normalized WL in 28nmFDSOI. 
This plot shows normalized power in 28nm LP and this plot shows normalized power in 28nm FDSOI. 
Overall, we achieve up to 24% WL reduction and 12% power reduction compared to S2D.  
SLIDE 37: IMPLEMENTATION-SPACE PARAMETERS AND TESTCASES
Now that we have discussed background and baseline 3D implementation flows, I describe the 3D power benefit estimation problem further. Modeling is difficult due to the high-dimensional space of implementation parameters. 
Here is list of various implementation-space parameters we use in our experiments. The parameters span across various constraints, layout contexts and technology choices.
SLIDE 38: FLOW AND TOP “10” PARAMETERS
To restrict the dimensionality and runtime of our modeling problem, we seek to explore the 10 most influential parameters. 
In our flow, we use engineered WLMs to perform synthesis. Then, we perform both 2D, A3D and Shrunk2D P&R. We use S2D as a proxy for 3D. 
For both P&R flows, we use scaled RC cap tables. We then extract parameters for modeling.
The top-10 parameters include six constraints such as clock period, max transition time, etc. We also use two implementation and two technology parameters such as utilization, multi-Vt libraries, respectively.  
SLIDE 39: MACHINE LEARNING METHODOLOGY
With parameters extracted from 2DIC implementation, we perform modeling. We use artificial neural networks to capture the complex interactions between parameters.  
We define the ANN architecture with one input and one output layer, plus two hidden layers. We search for the best number of the epochs of back propagation and the number of neurons per layer using the loop here to achieve bounded errors. 
We obtain our ground truth from S2D runs. 
SLIDE 40: MODEL ESTIMATE OF DELTA POWER
We use a wide range of IPs that resembles building blocks of modern SoCs. The table shows the list of our testcases. We use five types of testcases -- CPU, GPU, modem, multimedia and peripheral engine. 
This plot shows the actual percentage delta power benefit in the X-axis and the predicted values in the Y-axis for the five types of testcases. We derive separate models for each of the power components – internal, switching and leakage. Then we compose these models to create a model for total power.
We challenge ourselves to predict delta power. Across all our test data points, the worst-case error is 4.8% with S2D flow. With A3D flow, the worst-case error is 5.04% (-5.04%, 4.83%). 
SLIDE 41: MODEL VALIDATIONS
We do not have ground truth from true 3DIC implementations, so we must test if our 3DPE models are capable of returning unlikely predictions. 
We perform “stress testing” of the models. We perform Monte Carlo-like simulations by varying the mean and variance of each parameter in the models.
The figure shows a histogram of percentage predicted delta power. The maximum value is 39% for data points that are practically realizable. 
We reject data points that are not practically realizable. For example, data points in which the number of cells, utilization and the cell area are mismatched. Or, the wirelength and the number of cells are mismatched. 
SLIDE 42: MODEL-GUIDED IMPLEMENTATION
The hypothesis here is 3DPE should guide implementation if the predictions are reliable. We refer to this as model-guided implementation. We test this hypothesis with an implementation here.  This figure shows WLM cap in the X-axis and 3D power in the Y-axis. Minimum 3D power is achieved at 0.45pF. Our models predict the cap to be 0.75pF, using which the delta power is 0.34mW. Therefore, 3DPE model guidance is better than S2D by 5%. 

SLIDE 43: SUMMARY

In summary, power reduction is a key value proposition for 3DICs. Lack of a golden 3D flow makes prediction of 3D power benefits a difficult problem. 
We develop the 3DPE tool that predicts the percentage delta power benefits of 3DIC relative to 2DIC implementations. 3DPE is accurate within 5% error. 
We also propose stress testing and model-guided implementation approaches with 3DPE.

SLIDE 44: OUTLINE
I move on to the last topic in Thrust 1 – Back-end-of-Line or BEOL stack-aware routability prediction from placement. This has been accepted at ICCD 2016 recently. 
SLIDE 45: KEY TAKEAWAYS
Physical design is complex in advanced nodes due to multiple complex design rules that must be satisfied before tapeout. Currently, PD engineers use congestion maps to predict routability. This is largely an “art” because congestion maps alone cannot predict routability. Furthermore, due to lithography constraints, each metal layer is a sizeable percentage of the wafer cost. If the #metal layers, need to be increased due to incorrect routability prediction, the cost to company will be high.
My work identifies new parameters that comprehend design rule violations or DRCs and enable accurate routability prediction for 2D and 3D ICs using a learning-based methodology. I also demonstrate a novel prediction of Pareto frontiers of max achievable utilization, aspect ratio, #metal layers at iso-performance. 
SLIDE 46: TECHNOLOGY LIBRARIES
Before I describe the problem further, I provide background. . 
Here, we show dimensions of a minimum-sized 2-input NAND cell from 28nm FDSOI libraries. The tightest metal pitch is 0.1 micron for layer M2. The cell comes in 2 sets of track heights – 8T and 12T. Both have 2 Vt flavors – low and regular. The height of the 8T cell is 0.8 um, that is, 8 tracks multiplied by M2 pitch. The height of the 12T cell is 1.2um, that is, 12 tracks multiplied by 0.1um. The widths of the cell are different in 8T and 12T libraries. 
The 12T cells also have multiple channel lengths as shown in the bottom table. 
SLIDE 47: MACROS AND VIOLATIONS
This is the floorplan of Opensparc T2 spc design. The brown blocks are the SRAM macros and the blue rectangles are the standard cells. The white crosses denote violations of design rules flagged by the P&R tool. Most of these violations appear in the channel between macros, which indicates the channel heights must be increased or the macro orientations / placement must be changed. 
SLIDE 48: CONGESTION MAPS CAN BE MISLEADING
Now that I have described background, I describe the problem of routability prediction further.
The figure on the left shows congestion map at placement stage of a real design. The white regions show low congestion and red regions show high congestion. The figure on the right shows #DRCs at routing stage as white crosses. Many highly congested regions result in few (< 10) DRCs. Note that we can obtain #DRCs only at the routing stage, and not before. 
This figure on the left shows congestion map of another design and the figure on the right shows the #DRCs. In this design, few highly congested regions result in many DRCs. 
Making predictions of routability by only looking at the congestion map is incorrect. 
SLIDE 49: NEW PARAMETERS
We identify new parameters from only placement (i.e., no early or trial routing) that correlate well with DRCs.  We divide the placement region into grids of 45 x 45 tracks and correlate our new parameters and DRCs within each grid. 
Here, we show two such parameters. The top figure shows that sum of incoming and outgoing hyperedges or nets correlate well with #DRCs. It indicates that large #pins of a net within a grid cause DRCs. The bottom figure correlates minimum proximity of any pair of pins to DRCs. It indicates when pins of adjacent cells are too close to each other, then DRCs can occur.
SLIDE 50: LIST OF MODELING PARAMETERS
We list all our modeling parameters here. We divide the placement region into 45 x 45 track grids and obtain max, min and coefficient of variation statistics of the following: pin density, min proximity, #complex cells, sum of edges, #buried nets, etc. To differentiate between placements, we also use utilization, aspect ratio, clock period as parameters. To comprehend various BEOL stacks, we use #horizontal and vertical tracks as parameters. We also parametrize routing resources used by the power deliver network and density of vertical interconnects in 3DICs.  
SLIDE 51: INTERPOLATION, EXTRAPOLATION ALGORITHM
To predict Pareto frontiers from few, i.e., less than 20 placements, we develop an algorithm to interpolate and extrapolate parameter values. We pick three placements and obtain our list of modeling parameters. We pick another placement that we use to fit the model. We use weighted responses from SVM regression and MARS here. We then iterate to improve the model until the modeling error is smaller than an upper bound or we have used up all the 20 placements for modeling. Using this model, we now make predictions of parameter values, given inputs such as utilization, clock period, etc. 
SLIDE 52: PREDICTION OF ROUTABILITY IN 2D (28FDSOI, 8T)
Now we present our accuracy in predicting if a placement is routable in 28nm FDSOI and 8 track libraries. In the training set, we have 906 routable and 471 unroutable datapoints. In the testing set, we have 1597 routable and 503 unroutable datapoints. The top table shows the confusion matrices of the training and testing sets. The bottom table shows metrics of classification. In the testing set, our accuracy is 87%. Even though the number of unroutable datapoints are few, recall is 90% at 92.7% precision and the negative prediction value is 71%. 
SLIDE 53: PREDICTION OF PARETO FRONTIER
Here we present predictions of Pareto frontiers of max achievable utilization, aspect ratio, #metal layers at iso-performance, given only 20 placements. 
These are the Pareto frontiers of the ARM CORTEXMO design in 2D in 28nm FDSOI. The left figure is the ground truth or actual frontier and the right figure is the predicted frontier. At AR of 1.8, actual says 79% is the max utilization with 5 metal layers, whereas we predict that 78% is the max utilization. So, we are pessimistic by 1%. 
These are the Pareto frontiers of the ARM CORTEXMO design in 3D in 28nm FDSOI. For 3D, we have the A3D implementation flow. We show the frontiers of Tier 0 here. The left figure is the actual frontier and the right figure is the predicted frontier. At AR of 2.0, actual says 89% is the max utilization with 5 metal layers, whereas we predict that 88% is the max utilization. So, we are again pessimistic by only 1%. 
SLIDE 54: SUMMARY
In this work, we demonstrate that new modeling parameters are needed to predict routability, given BEOL stack-aware placement. We devise an interpolation and extrapolation algorithm to predict Pareto frontiers. Our methodology is applicable to 2D and 3D ICs with classification accuracy of greater than 86% across multiple designs and technologies. Our predictions of max utilization are within 2% of the actual max utilization.
SLIDE 55: OUTLINE
In Thrust 2, I present one new work that predicts interconnect coupling delay and transition effects. This has been presented at SLIP 2015. 
SLIDE 56: KEY TAKEAWAYS
Many tools perform timing analysis in both signal integrity or SI mode and non-SI mode. Runtimes in SI mode are 3x as large as runtimes in non-SI mode, also the slack divergence between SI and non-SI is large. The modeling problem is difficult because timers use proprietary timing engines. Alignment of aggressor-victim windows can be complex. We propose learning-based modeling of electrical signals at the gate- and wire-level using a layered modeling approach to address these issues. 
I provide only salient highlights of this work  as I had presented a very similar flavor of this work in UQE. But, this is a harder problem as we use the same tool for correlation. 
SLIDE 57: SI VS. NON-SI GAP IN STA TOOLS
Let’s examine how much do SI and non-SI reports of the STA tool differ. This plot shows path slack in SI mode in the X-axis and path slack in non-SI mode in the Y-axis.
The divergence can be as large as 81ps in the critical path at a clock period of 1.0ns. 
81ps is equivalent to 4 stages of logic in 28nm, leading to 20% performances difference. This is equal to one node of Moore’s scaling.
SLIDE 58: SI TO NON-SI  CALIBRATION USE CASE
Instead of using STA tools with SI capability, we can first generate non-SI timing reports, and then use SI to non-SI calibration model to generate SI timing reports. In this way, we do not need STA tool with SI capability
Thus, we only need to spend 100K dollars and maybe 2 hours/per design, instead of 250K and 6hours per run, to get the precision of SI timing analysis.
SLIDE 59: LIST OF MODELING PARAMETERS
We develop three models based on our observation of modeling parameters. We first model incremental transition time. Then we model incremental delay due to SI based on transition time model and other parameters. Finally we model SI-aware path delay base on incremental delay model and other parameters.
Here we list all the parameters that are used for modeling, and their respective sources.
These include electrical layout logic structure parameters and constraint. These can be obtained from spef, non-SI report, library and SDC files.
SLIDE 60: ACCURACY OF PATH DELAY PREDICTION
We show the path delay prediction. Worst-case absolute error is 8.2ps and the average absolute error is 1.7ps 
SLIDE 61: ROBUSTNESS OF MODELS
The previous results show acceptable correlations, but what about the ability to predict the unseen data? We implement a JPEG design with different clock period, number of stages and utilization, and we assess prediction of our models on this implementation. 
The x-axis is the actual SI incr delay and the y-axis shows the predicted SI incr delay. 
The worst-case absolute error is 7.9ps which is 12.3% of the actual SI incr delay, while the average absolute error is 1.6ps, 2.6%.
This indicates that our model can predict other implementations, thus our model is not overfitted. 
SLIDE 62: SUMMARY
Calibration of non-SI to SI enables cost and runtime saving for SoC design. Because of this, we analyze electrical logic structure and layout parameters between non-SI and SI modes, in order to model the SI from non-SI. We develop machine learning-based models to accurately calibrate non-SI to SI timing. 
We achieve worst-case error of 8.2ps in 28nm foundry FDSOI technology. Recent validations on 7nm technology achieve similar quality of predictions. Further validations are ongoing to test robustness of models. 
SLIDE 63: OUTLINE
Thrust 3 of my thesis presents three works on optimizations of design power, energy, project management, and cost. First, I present a new analytic 3DIC placement that uses a new “true 3D” objective that reduces design power. This work has been submitted to ASP-DAC 2017. 
SLIDE 64: KEY TAKEAWAYS
As mentioned in Thrust 1, 3DICs offer substantial scaling possibilities for the semiconductor industry. But, no golden 3D flow and tooling exists today. The strongest academic flow, Shrunk2D or S2D, invokes commercial 2D P&R and partition the netlist using minimum #cuts. Our new analytic placement tool, APlace3D or A3D, implements a true 3D objective. Our solutions are routable in a commercial P&R tool and we perform signoff timing and power analyses. 
A3D enables better prediction of Pareto frontier of max utilization, aspect ratio and #metal layers in 3D and 3D power benefit. 
SLIDE 65: SUMMARY
3D is a promising technology but it calls for new true 3D implementation flows. We propose a new analytic 3D placer whose solutions are routable in a commercial P&R tool. We achieve significant WL and power reductions compared to 2D and S2D. Compared to 2D, A3D achieve 31% reduction in WL and 20% reduction in power. Compared to S2D, A3D achieves 24% reduction in WL and 12% reduction in power.  
We have validated A3D on multiple technologies and designs. 
SLIDE 66: OUTLINE
The second work in Thrust 3 is about optimizations of project management and cost. This work has been submitted to TODAES 2016. 
SLIDE 67: KEY TAKEAWAYS
Large IC design companies spend 100s of millions of dollars per year on design infrastructure to meet tapeout schedules for multiple concurrent projects. The problem is difficult because there are many types of resources, they are limited and must be shared across projects. There are also complex co-constraints between resources. For example, at most two cores can be used for every license of PTSI. 
We develop two new mixed integer-linear programming formulations that extend the resource constrained project scheduling problem formulated and solved by Kolisch et al. We achieve significant cost and schedule savings compared to solutions adopted by a top-5 IC design company. We refer to this company as Company X. Better predictions lead to better optimizations as constraints to the optimizer can be predicted accurately (e.g., storage, engineers)
SLIDE 68: CHALLENGE: MULTIPLE RESOURCE TYPES
Before describing the problem, I provide background. 
IC design companies typically working on multiple simultaneous projects e.g., application processor, audio DSP, video DSP, etc. 
Each project has multiple activities such as synthesis, verification, place-and-route, extraction, timing analysis, etc. Each activities consumes one or more resources such as compute cores, storage, memory, EDA tool licenses, engineers, etc. 
Co-constraints can exist between resources, e.g., at most 2 compute cores can be used for every PTSI license. 
Resources can be of 3 types. 
Fully-shared resources are shared across all projects from a common pool. Examples include compute cores in a datacenter.
Segregated or dedicated resources are allocated exclusively to a specific project. Examples include storage and engineers. 
Conditionally-shared resources are allocated to each project, but any resource unused by a project may be used by other projects. Examples include EDA tool licenses, engineers. 
SLIDE 69: EXAMPLE: INFEASIBLE ALLOCATION 
Here is an example of infeasible allocation of resources across three projects A, B and C. Each project has one activity and one resource type. The upper bound of fully shared resources is 20. The upper bounds of number of segregated resources projects A, B and C are 5 each. The upper bounds of number of conditionally-shared resources for projects A, B and C are 5 each, as well. 
The number of fully shared resources consumed by each project is 3, 2 and 1, respectively, so the sum is less than 20. The number of segregated resources consumed is also less than the upper bounds. The number of conditionally-shared resources consumed by A is 0, by B is 2, but by C is 6. This violates the upper bound. The number of unused conditionally-shared resources consumed by C is 9, which again violates the upper bound of 5. 
Conditionally-shared resources are allocated to each project, but any resource unused by a project may be used by other projects. Examples include EDA tool licenses, engineers. 
SLIDE 70: EXAMPLE: FEASIBLE ALLOCATION
Here is an example of feasible allocation of resources for the same example in the previous slide.  
The number of fully shared resources consumed by each project is 3, 2 and 6, respectively, so the sum is less than 11. The number of segregated resources consumed by C is 5. The number of unused conditionally-shared resources consumed by C is 5. So, all constraints are satisfied.  
SLIDE 71: SCHEDULE COST MINIMIZATION (SCM) FORMULATION
Now that I have described background, I describe our formulations. 
The objective of our schedule cost minimization or SCM problem is to minimize the total cost or the sum of schedule penalties of all projects. This is subject to constraints on start and finish times, activity precedence, max number of resources, resource requirements. These are similar to the RCPSP formulation. New are resource co-constraints, stability in resource allocation constraints and tethering forecast resource allocation constraints. 
The complexity is O(4NKJ(i)T) variables, where N is the #projects, J(i) is the #activities for each project I, K is the #resources and T is the max duration over all projects.
SLIDE 72: RESOURCE COST MINIMIZATION (RCM) FORMULATION
The objective of our resource cost minimization or RCM problem is to minimize the total #resources and cost of all projects. This is subject to constraints on start and finish times, activity precedence, max number of resources, resource requirements. New is the stability in resource allocation constraints. 
The complexity is O(NKJ(i)T) variables.
SLIDE 73: USE CASE: HANDLING LATE-BREAKING BUG
Using the instance from the previous slide, we demonstrate application to another use case. Project 2 has a late-breaking bug in activity 7, so it delays all activities from 8 to 11.  Company X’s solution took 41 extra days to complete. However, our MILP solutions take 34 extra days to complete. That is, we save 7 working days of 1.4 work-weeks. This is significant because Moore’s Law advances by 1% per week.
SLIDE 74: USE CASE: SCHEDULING TETHERED TO FORECASTS
Here, we demonstrate another use case in which scheduling is tethered to forecasts. This picture shows resource allocation for one project. The picture on the right shows an allocation of 3 projects. The allocation is infeasible because the #servers during weeks 30-36 exceed the datacenter capacity. Company X could not solve this problem and ended up purchasing 600 additional servers. 
The figure at the bottom shows our MILP solution. Our solution meets the schedule without the need for any additional servers. We save cost of 600 servers. 
SLIDE 75: USE CASE: HUMAN RESOURCE ALLOCATION
Here is a RCM use case using an instance from Company X which has 4 projects, 8 activities per project, four types of engineers and max duration of 16 work-weeks. This figure shows the activity precedence of these 8 activities. The table on the right shows billable man-weeks for each project and activity. 
The plot below compares MILP and Company X’s solutions. We reduce #max resources by 37.5%. At a non-US location, the total cost-savings is $5.2M within ½ year project scheduling makespan. 
SLIDE 76: SUMMARY
Lack of project management tools can impact a IC company’s bottom line by many millions of dollars annually. We develop new formulations by extending the RCPSP formulation. Our solver can be applied for fiscal planning and for “what-if” analyses by program management. Application to industrial instances results in significant cost and schedule savings.
SLIDE 77: OUTLINE 
The third work in Thrust 3 optimizes design performance. This work has been presented at ISQED 2014. 
SLIDE 78: KEY TAKEAWAYS
Reliability is a key processor design consideration at advanced nodes to guarantee system lifetime. No existing scheduling policy guarantees both acceptable performance and acceptable throughput. This is because optimal solution requires new ways to perform discretized exhaustive search. 
We develop a maximum-value reliability-constrained overdrive frequencies or MVRCOF formulation that guarantees both acceptable performance and acceptable throughput. 
SLIDE 79: RELIABILITY IN MULTI-CORE SYSTEMS
Modern multicore processors, such as the Intel Xeon, AMD Athlon, etc. operate at multiple operating modes to meet different performance and power requirements. For example, nominal, supply voltage scaling and turbo.
Task scheduling affects how each core in a multicore processor is used. A subset of cores can fail before others.
Applications have different requirements of the number of cores to use. The operating system scheduler packs tasks from applications using some or all of the available processing cores. 
The figures show how Applications A on the top and B at the bottom have different requirements for the number of cores during its execution phase. 
The figure on the right shows percentage active time on the Y-axis and number of active cores in the X-axis for Application A in blue and Application B in maroon. The green bars show how cores are used when the scheduler packs tasks in a eight-core system. The core usage is roughly a Gaussian distribution with the mean being the total of the available cores divided by two. 
SLIDE 80: OPTIMAL, HEURISTIC VS. BASELINE (RC-LG)
Here, I present only our key results. This figure shows the objective function value in Y-axis and the testcases in the X-axis. The figure compares the objective function values across optimal, heuristic and the baseline solutions. 
Our optimal solutions achieve up to 17.4% higher value of objective function as compared to baseline solutions as shown by the arrows and percentage numbers in white. Our heuristic solutions can be up to 3.3% worse than our optimal solutions as shown by the arrow and percentage number in blue. 
SLIDE 81: SUMMARY 
We formulate and solve a new MVRCOF problem under lifetime reliability constraints. 
We develop a MVRCOF solver that implements our optimal and heuristic flows.
Our solutions guarantee both “acceptable performance” and “acceptable throughput” and we empirically demonstrate that our optimal solutions can achieve up to 17.4% greater value in objective function as compared to baseline RC-LG solutions. 
SLIDE 82: PERSPECTIVES: MAINSTREAM VS. PIONEERING
We classify works presented into mainstream and pioneering. Mainstream works make improvements of existing methods or flows. Pioneering works provide a novel way of approaching the problem. 
Mainstream works include routability prediction, 3DIC, project management and task scheduling. In each of these, this thesis makes several new contributions.
Pioneering works include ORION3.0 and signoff timing correlation. In ORION3.0, we demonstrate a novel modeling approach at the architecture-level using post-P&R data to fit models. In signoff timing correlation, we demonstrate approaches to modeling circuit phenomena and model-guided PD optimizations. 
SLIDE 83: PERSPECTIVES: NEW THINKING AND FOLLOW-ON
Works in this thesis that are suitable for follow-on research include integrating signoff timing correlation models with timing optimization loops, modifying formulation of SCM so that timesteps can change automatically when schedule changes occur, and iterative optimizations to obtain more stable solutions. MVRCOF formulation can be applied to traces of workload from datacenters and solutions can be validated in a datacenter LSF framework. The Pareto frontier prediction work can be extended to perform SoC-level Pareto prediction. 
This thesis provides new directions / thinking through some works. Early-stage slack prediction may be adopted for early-stage prediction of power, DRCs, IR drop or other design QoRs. New thinking is also required to reduce the “trial and error” nature of model fitting, e.g., using grid search, incremental modeling, etc. Possibly domain understanding can help here. Signoff timing correlation can be extended to correlate power, reliability. Project management formulations can spur thinking in robustness of scheduling in the face of stochasticity in resources and personnel. 
SLIDE 84: CONCLUSIONS
In conclusion, this thesis presents wide-ranging opportunities for learning-based modeling in IC design and shows new applications using the three thrusts. We attack qualitatively new challenges and present innovations in modeling and optimization methodologies.
SLIDE 85: ACKNOWLEDGMENTS
This thesis would not have been possible without the constant guidance, mentoring and support of my advisor, Prof. Kahng. I thank my committee members – Professors Cheng, Lin, Rao and Saul. I would like to thank my labmates for all their help and support. I thank my mentors, Prof. Lin, Dr. Samadi and Dr. Chan. I would also like to thank all my co-authors, and Shrunk2D authors at GT. 


SLIDE 1: TITLE
Thank you for the introduction. My talk is on “Optimal Reliability-Constrained Overdrive Frequency Selection in Multicore Systems”. This is joint work with professor Kahng at UCSD.
SLIDE 2: OUTLINE
My talk is structured as follows. I begin with motivation followed by previous work, contributions of our work, the problem formulation, flow of our optimal (discretized) solution, and our experimental setup and results. Finally, I conclude.
SLIDE 3: RELIABILITY IN MULTICORE SYSTEMS
Modern multicore processors, such as the Intel Xeon, AMD Athlon, etc. operate at multiple operating modes to meet different performance and power requirements. For example, nominal, supply voltage scaling and turbo.
Reliability is a key design consideration at leading-edge technology nodes to meet a prescribed system lifetime.
Task scheduling affects how each core in a multicore processor is used. A subset of cores can fail before others.
SLIDE 4: SCHEDULING IN MULTICORE SYSTEMS
Applications have different requirements of the number of cores to use. The operating system scheduler packs tasks from applications using some or all of the available processing cores. 
The figures show how Applications A on the top and B at the bottom have different requirements for the number of cores during its execution phase. 
The figure on the right shows percentage active time on the Y-axis and number of active cores in the X-axis for Application A in blue and Application B in maroon. The green bars show how cores are used when the scheduler packs tasks in a eight-core system. The core usage is roughly a Gaussian distribution with the mean being the total of the available cores divided by two. 
SLIDE 5: CORE WEAROUT
Cores wear out when they are active. Mean time to failure or MTTF is a measure of a core’s lifetime. Reliability mechanisms such as, electromigration,  etc., degrade a core’s MTTF.  We focus on MTTF degradation due to EM. When all cores are not simultaneously active, the OS scheduler can schedule tasks such that cores wearout in a balanced manner.


SLIDE 6: IMPACT OF OVERDRIVE FREQUENCY
To meet performance and throughput requirements, cores are overclocked. 
The overdrive frequencies cause faster MTTF degradation due to elevated temperatures.
And results in two challenges.
The system can violate an “acceptable throughput”, that is, cores fail before all assigned tasks are completed. OR
The system can violate a minimum “acceptable performance” , that is, cores operate at less-than-desired frequencies.
SLIDE 7: TERMINOLOGY
Before I proceed with the remaining talk, I will introduce terminology used in our work.
Power-on-hours is the effective number of lifetime hours consumed and is a measure of a core’s lifetime degradation due to operating conditions.  
Nominal temperature is the temperature at which MTTF degradation is the same as the number of hours a core is active. 
Acceleration factor is the ratio of original MTTF at nominal temperature to the actual MTTF at higher-than-nominal temperature. 
SLIDE 8: OUTLINE 
Let us examine previous works that study the impact of task scheduling on reliability. 
SLIDE 9:  CLASSIFICATION OF EXISTING WORKS
We use the following labels to classify existing works. The letter “N” before any label signifies a Non or No. For example, RC is Reliability Constrained and NRC is Non-Reliability Constrained, LG is lifetime guarantee and PG is performance guarantee. 
Reiss12 is NRC, NLG and NPG. They describe how to maximize throughout by stressing cores to operate at their maximum temperature.  Karpuzcu09 is RC but NLG and NPG as they describe how to maximize performance by degrading a subset of cores.
Several works are examples of RC, LG and NPG. They provide various dynamic policies. However, none of them provide any performance guarantees. 
SLIDE 10: COUNTEREXAMPLE TO NRC POLICIES
In our paper, we provide counterexamples to existing works with numerical examples. Consider a task schedule as shown in the table on the right for a system with four cores. There are nominal as well as overdrive tasks that require between one and four cores to be active. 
NRC policies run cores at the max frequency of 3GHz. By calculating POH we can determine that cores fo not have sufficient lifetime to execute the overdrive tasks at m = 3. In addition, no task requiring m = 4 can be completed. 
Therefore, NRC policies cannot guarantee “acceptable throughput”. 
SLIDE 11: COUNTEREXAMPLE TO RC-LG POLICIES
For the same task schedule, RC-LG policies will initially execute cores at 3GHz and later drop to 1.6GHz to meet lifetime. Again by calculating POH, we observe that all tasks requiring three and four active cores will operate at 1.6GHz, that is, less than the acceptable 1.8GHz.
Therefore, RC-LG policies  cannot guarantee “acceptable performance”. 
SLIDE 12: OUTLINE
So, what do we do differently?
SLIDE 13: WHAT DO WE DO DIFFERENTLY?
We formulate a new Maximum-Value Reliability-Constrained Overdrive Frequencies or MVRCOF optimization problem. This is solved offline.  Our formulation is important because the overdrive frequencies are the optimization variables and the value is the user experience when the overdrive frequencies are maximized.
We guarantee prescribed levels of “acceptable performance” and “acceptable throughput”. 
SLIDE 14: COMPARISON OF OURS VS. EXISTING WORKS
Recall that existing RC-LG works provide no performance guarantees. In our work, we provide performance guarantee in addition to lifetime guarantee under reliability constraints. 
SLIDE 15: WHAT IS THE OPTIMAL SOLUTION?
Our formulation can determine the optimal solution for the same scheduling problem for which existing NRC and RC-LG policies are suboptimal. Using exhaustive search we determine the overdrive frequencies as shown in the bottom table. Note that all our overdrive frequencies meet the minimum “acceptable performance” requirement as well as guarantees  “acceptable throughput”. 
SLIDE 16: OUR KEY CONTRIBUTIONS
Our key contributions are
We develop a new MVRCOF formulation to maximize the value of operating multiple cores at overdrive frequencies.
Our solutions guarantee both “acceptable performance” and “acceptable throughout”. 
We propose an optimal (discretized) solution flow using exhaustive search as well as an approximate heuristic flow
We empirically determine our optimal solutions improve the objective function value by up to 17.4% as compared to existing works. 
SLIDE 17: OUTLINE
Now I describe our problem formulation. 
SLIDE 18: FORMULATION
This slide presents our formulation in a formal manner
SLIDE 19: FORMULATION IN ENGLISH
We maximize the sum of the product of weight, frequency and execution times in nominal and overdrive modes across all m. The execution times multiplied by frequency determines the duration for which cores operate at a given frequency.
SLIDE 20: FORMULATION IN ENGLISH
Our first constraint ensures a lower bound on “acceptable performance”, that is, 30% above the nominal frequency. 
The second constraint guarantees all tasks are completed within system’s lifetime and cores wearout in a balanced manner. 
The third and fourth constraints are upper bounds on instantaneous power and temperature.
SLIDE 21: MVRCOF INPUTS: TASK DESCRIPTION
Our formulation has two kinds of inputs: Task description and system description.
The OS scheduler obtains core usage and performance requirements from applications and determines the total execution times in nominal and overdrive modes,  the weights and the nominal frequencies. 
SLIDE 22: MVRCOF INPUTS: SYSTEM DESCRIPTION
An SoC designer provides details on the number of available cores, maximum power of any core, maximum frequency achieved by a core, maximum die temperature, nominal temperature and the intial MTTF of each core.
SLIDE 23: MVRCOF OUTPUTS
The MVRCOF solver outputs the optimal overdrive frequencies, percentage time in each combination of active cores. For example, in a three-core system, two cores can be active in 3 ways. And the percentage of lifetime each core executes in nominal and overdrive modes. 
SLIDE 24: MVRCOF INPUTS AND OUTPUTS
The inputs are provided to our MVRCOF solver to obtain the outputs. 
SLIDE 25: OUTLINE
SLIDE 26: OPTIMAL (DISCRETIZED) SOLUTON FLOW
This slide shows our optimal (discretized) solution flow. It is discretized because we consider discrete overdrive frequencies within a range.
For each core and for each combination in which the core is active, we perform power and thermal simulations using discrete values of overdrive frequencies and generate a one-time lookup table of all possible values of overdrive frequencies, temperature and acceleration factors.  
Now, we perform exhaustive search using values from this table to maximize the value of our objective function. 
SLIDE 27: HEURISTIC FLOW
Recall our objective function. We maximize the overdrive frequencies in the order of maximum value of the product of weight and execution times of a set of active cores. For example, in a three-core system if the product of two active cores is greater than three and one active cores. We determine the overdrive frequencies for two cores, followed by three cores and one core. 
SLIDE 28: OUTLINE
I describe our experimental setup, testcases and present results now. 
SLIDE 29: EXPERIMENTAL SETUP
To resemble realistic  vector processor-like core, we use 72 copies of the jpeg_encoder from OpenCores. We perform synthesis, place and route using commercial tool flows and 45nm foundry libraries. 
We perform power simulations with Synopsys PTPX. We increase voltage from 0.8V in steps of 10mV to 1.2V and frequency from 1.5GHz in steps of 50MHz to 3GHz.
We perform thermal simulations using HotSpot and our LP solver is lp_solve. We use RC-LG policies as the baseline policy for comparisons. 
SLIDE 30: TESTCASES
We develop our own testcases by configuring  various parameters. 
We develop eight testcases in total.  
An example of a testcase with N = 4 is shown in the table below. The bold red numbers show that for four active cores, the nominal execution time is 2000h, overdrive execution time is 5000h and the corresponding weights are 0.4 and 0.6 respectively.
SLIDE 31: OPTIMAL, HEURISTIC vs, RC-LG 
Here, I present only our key results. This figure shows the objective function value in Y-axis and the testcases in the X-axis. The figure compares the objective function values across optimal, heuristic and the baseline solutions. 
Our optimal solutions achieve up to 17.4% higher value of objective function as compared to baseline solutions as shown by the arrows and percentage numbers in white. Our heuristic solutions can be up to 3.3% worse than our optimal solutions as shown by the arrow and percentage number in yellow. 
SLIDE 32: RUNTIME COMPARISON
This figure shows normalized runtime in the Y-axis and testcase in the X-axis. Although our heuristic solutions can be up to 3.3% worse than our optimal solutions, the runtime can improve by up to 10x. 
SLIDE 33: OUTLINE
I now conclude my talk.
SLIDE 34: CONCLUSIONS
We formulate and solve a new MVRCOF problem under lifetime reliability constraints. 
We develop a MVRCOF solver that implements our optimal and heuristic flows.
Our solutions guarantee both “acceptable performance” and “acceptable throughput” and we empirically demonstrate that our optimal solutions can achieve up to 17.4% greater value in objective function as compared to baseline RC-LG solutions. 
Our future works include application of our methods to traces from real server workloads, expand our methods to handle other objectives and achieve solutions that are temperature history-aware.
Thank you for your attention. 
Title
Good morning. Thank you for being my committee professors. The title of my thesis and this presentation is improved physical design and signoff methodologies for better integrated circuit design quality. 

Slide
This slide shows the outline of my thesis. There are four chapters in my thesis. The first chapter gives an overview. The following three chapters present three optimizations to address three major challenges in physical design and signoff. 

(Q: what is physical design and what is signoff ?)

The three major challenges are complex operating conditions, demand for low-power designs and growing design margins. And my three chapters are multi-mode multi-corner optimization, low-power optimization and mixed-fabric optimization. I will give details regarding the challenges and the proposed optimizations in the following slides. 

Slide 
This slide shows my publications during my Ph.D. study. 

Slide
Now I will discuss some motivation and more details about my thesis. As noted by ITRS, the realizable transistor density scaling in actual MPU products has slowed down from traditional 2X per technology node to 1.6X per technology node. 

The figure shows that there is a design capability gap between the available scaling and realizable scaling.

(Q: what is density? what is available scaling? what is realizable scaling? MPU?)
 
To compensate the design capability gap, we pursue design-based equivalent scaling, that is, to rely on design technology improvement to achieve performance, power, area and cost tradeoffs to rescue Moore’s-Law scaling of value.

As key steps in IC design, physical design and signoff need to be improved to achieve design-based equivalent scaling. 
Moreover, there are physical design and signoff also face many challenges. 

Slide 
This slide summarizes the major challenges in physical design and signoff. 

The first challenge is the complex operating conditions and corner explosion. High-performance and low-power designs typically have multiple operating modes such as turbo mode and nominal mode. The multi-mode operation requires multi-mode signoff. 
In addition, there is test mode, of which the timing and power can also be critical. Test mode optimization must no degrade QoR in function mode.  
Further, there is ping-pong effect during multi-mode optimization, that is, optimization at one mode can cause timing violations in other modes. 
So, we see that multi-mode multi-corner optimization is a challenge. 

The second challenge is the demand for low-power designs. 
Power reduction has been viewed as a grand challenge in ITRS. Moreover, low-power techniques will increase design complexity and introduce power overheads. Therefore, we must ensure that the power benefits from these techniques outweigh their costs. And since there are urgent requests for low-power designs, aside from commonly used techniques, new techniques need to be proposed.  

(Q: list low-power techniques)

Last challenge is the growing design margins. Due to increased design complexity, process variation and reliability constraints, designers use overdesign to ensure correctness of the design. However, such margins will reduce potential benefits from technology scaling. 

(Q: what is margin?)

Slide
To pursue design-based equivalent scaling and address the challenges for better design QoR, my thesis presents improve physical design and signoff methodologies. 

This figure shows the scope of my thesis. As discussed, three chapters address three major challenges. And details of each chapter is also described.

Slide
In this presentation, I will present three works. One from the multi-mode and muti-corner optimization chapter, two from low-power optimization chapter.    

Slide
The first work is comprehensive optimization of scan chain timing during late-stage IC implementation. This is a joint work with Samsung. 


Slide 
This slide gives a brief introduction on scan chain. 
Scan chain technique is commonly used in design for test. It provides a simple way to set and observe all flip-flops. The bottom figure shows an example. In the example, there are three scan flip-flops. They form a scan chain. 
There are three stages during scan test. During the scan in stage, we shift in and load all flip-flops with an input vector. Then the capture stage excites combinatorial logic and capture outputs at flip-flops. Finally, during the scan out phase, we shift out the captured output vector and check whether there is an error. 

The scan in and scan out together is called scan shift stage, which takes much test time due to large number of cycles. In this work, we optimize scan shift timing.

Slide 
Scan timing, especially scan shift timing, is important to test time, test cost and test robustness. 
In this talk, I will discuss two scan timing issues.
First, since the number of logic instances along a scan timing path is typically small, scan timing paths are vulnerable to hold violations. As a result, many hold buffers are inserted, which increase design area and routing congestion. 
Second, scan shift is typically performed at a high frequency. The corresponding high power will incur large dynamic voltage drop. And the large DVD further degrades scan timing and leads to “false failure” during test.
To address these two issues. Our goals in the work are to perform scan ordering for hold buffer reduction and to insert gating logics to minimize timing degradation due to dynamic voltage drop. 
These problems are not new. But do previous approaches really solve these problems?

Slide
Most of previous approaches optimize scan chain during early design stages, such as synthesis and placement. 
However, the hold-critical paths and DVD hotspots can very between early and late design stages. 
This figure shows that the hold-critical scan timing paths, which are in red, change between the post-placement and post-routing stages. The difference might come from the impact of clock skew and interconnect delay.
This figure shows large difference of DVD map between the post-placement and the post-routing stages. The difference might come from the clock buffers and timing optimizations during routing, such as sizing and buffering. 

Since the hold timing and dynamic voltage drop vary between early and late design stages, an early-stage scan chain optimization might be misleading. We therefore propose optimizations during late-stage IC implementation. 

However, the late-stage optimization is not trivial. It has to consider the timing impact on datapaths in function mode. It also needs to minimize the area and power overheads to avoid design QoR degradation. 

Slide
Now, I will first describe our methodology for scan ordering for hold buffer removal. 
We define the post-routing scan ordering problem as Given a routed design, timing constraints and upper bound on wirelength penalty, we perform scan ordering to minimize the number of hold buffers. 

Slide
Before descrbing our methodology for scan ordering, we first study the causes of hold violations on scan timing paths. 
This figure shows the skew distribution of scan timing paths with hold buffers. We see that majority of hold-critical paths has negative skew values.

This figure shows distances between the launch and capture flip-flops versus their hold slacks. We see that smaller distances lead to smaller hold slacks.

Slide
Based on these observations, we perform optimizations to achieve greater incidence of positive skew values and slightly increase start-end flip-flop distances, to remove hold buffers. 

Slide
This slide shows the pseudo code of our scan ordering optimization. We iteratively perform two-opt optimizations along the scan chain and update the ordering solution with the one with smaller number of hold buffers. 
The right figure shows an example of scan ordering to exploit clock skew for hold buffer removal. 
In our scan ordering optimization, we do not allow timing degradation on datapaths and additional hold violations. And our optimization always meets a predefined upper bound on wirelength penalty. To honor a fixed scan chain ordering, a subchain with fixed ordering is merged into one node before our optimization. 



Slide
Now I will describe our methodology of DVD-aware gating insertion. We define the problem as Given a routed design, timing constraints, power information and upper bound on area overhead, we perform gating insertion to maximize the minimum DVD-aware slack.

Slide
This slide shows our overall gating insertion flow. We first determine the DVD hotspots to optimize. Here a DVD hotspot is a grid with large dynamic voltage drop. Note that we only consider the DVD hotspots having impact on scan timing slacks. We also note that the worst DVD hotspot is not necessarily the same as the hotspot with the largest timing impact. 

Second, we find gating locations within a netlist to reduce the dynamic power within the selected DVD hotspots. We also minimize the number of gating logic insertions to minimize the area overhead.

Last, we perform ECO-based gating insertion.

The figure shows the schematic of gating insertion. Note that we also insert gating logics inside the logic cone. 

I will discuss the details of each step in the following slides. 

Slide
We formulate an integer linear program to select DVD hotspots We select a limited number of DVD hotspots to optimize so as to maximize the minimum DVD-aware slack. 
Our ILP formulation is shown here. As mentioned, we maximize the minimum DVD-aware slack. The first constraint estimates the slack improvements from DVD reductions within the selected DVD hotspots. The second constraint ensures that a DVD hotspot is selected if any cell within it is gated. The third constraint enforces an upper bound on the number of the selected DVD hotspots.

Slide
We perform netlist traversal to find gating locations. Our objective here is to minimize the dynamic power within selected DVD hotspots. A simply example is shown in the figure. In the example, in red are cells within the selected hotspots and in white are candidate gating locations. We first assign a gain of one to each cell within the selected hotspots. We then propagate the gain values from each cell within the selected hotspots backwards based on the number of fanins. Last, we select the gating location with the maximum gain value. 
In the last step of our optimization, we perform a matching optimization between available white spaces and gating logics and insert gating logics as ECO steps. 

Slide
This slide shows our experimental setup. We perform experiments in 28LP technology. The tools we use are shown here. We use four designs shown in the table as our testcases.

Slide
This slide shows our scan ordering results. We use the default SP&R flow based on commercial tools as our reference flow. We see from the table that our optimization achieves 82% hold buffer reduction and with very small wirelength penalties. 

Slide
This slide shows our gating insertion results. Again, we use the default SP&R flow as our reference flow. We see from the table that our optimization achieves up to 58% improvement of DVD-induced slack degradation. Our optimization achieves this with small number of gating logics. Therefore the area penalty is small. We also see that the worst DVD is not significantly optimized. This indicates that the worst DVD does not necessarily correspond to the worst DVD-aware slack.

Slide
We propose comprehensive scan timing optimization during late-stage IC implementation. We validate our optimization with a realistic implementation flow. Our optimization leads to up to 82% hold buffer reduction and up to 58% improvement of DVD-induced scan timing degradation. 
Our future works are listed as follows. 

SLIDE
The second topic for today’s presentation is improved flop tray-based design implementation for power reduction.

SLIDE
First, a flop tray here is a multi-bit flop-flop, which is a combination of flip-flops
We know that the application of flop trays can significantly reduce the number of sinks in a clock tree, thus reducing clock tree wirelength and clock power.
As a simple calculation, in a given clock tree, if we replace all the single-bit flops with 64-bit flop trays, we are able to reduce the number of clock buffers by 98%.
Further, if we assume a clock tree has 100K sinks and fanout of eight at each level, by replacing all the single-bit flops with 64-bit flop trays, we can reduce the clock tree depth from six to four. 

From these examples, we can see that the usage flop trays can significantly reduce the number of clock buffers and clock power. 
I will show additional benefits from flop trays in the next slide.

SLIDE
This figure shows a single-bit flip-flop.
We see that each flop generates its own clock signals with two inverters.
In a flop tray, the inverters for clock signals can be shared, which reduces power and area of flops.
As an example, a recent work achieves 22% flop power reduction by using 2-bit and 4-bit flop trays.
So, we see that the usage of flop trays not only reduces clock power but also power and area of flop itself.
However, implementation of flop tray-based design is not trivial. I will show several challenges in the following slides.

SLIDE
First, flops occupy large portion of block area. As an example, in one of our testcases, VGA, 30% of instances are flops, which takes 51% of the block area. Therefore, the optimization of flops and flop trays has significant impact on design quality. 
Second, flop trays can have high aspect ratio and distinct size. As shown in the bottom figure, the 64-bit flop trays, which are in orange, have very high aspect ratio. Unable to comprehend the dimension of flop trays will result in degraded solution quality. 
Third, clustering of flops for flop tray generation imposes additional placement constraints, which can easily increase routing congestion and power penalty. 
So we see that there is a tradeoff between flop tray benefits versus datapath power penalty. In other words, if we only use small flop trays, we cannot fully exploit the benefit of flop trays. On the other hand, using large-size flop trays may sacrifice datapath wirelength and power.
This figure shows power and wirelength overheads on datapath from a logical clustering flow, where we use commercial tools to cluster flops during the synthesis stage. We can see up to 40% increase in wirelength, and up to 16% increase in datapath power due to flop tray generation.

Therefore, we must ensure that the benefits of using flop tray outweigh its costs.

SLIDE
This slide shows our overall optimization flow. In blue are our proposed optimizations. We first synthesize the netlist with only single-bit flip-flops. We then place the synthesized netlist with only single-bit flops. We consider such an initial placement solution as a relatively good placement solution in terms of routing congestion and datapath timing and power, since there is no additional placement constraint from flop clustering. 

Based on the initial placement solution, we perform flop clustering and generate flop trays. Our objective here is to minimize the displacement of flops as well as timing and power impact on datapath. These indicate that we want to maintain the solution quality of the initial placement as much as possible. At the same time, we also minimize the number of flop trays to reduce clock power and power of flops. 

Our separate study shows that it is practically impossible to optimally optimize flop clustering and flop tray placement simultaneously with all possible flop tray sizes. 
We therefore perform a two-step optimization. The first step is a capacitated K-means clustering, as shown in the dotted box, in which we generate optimal clustering solutions for each flop tray size. We then perform ILP-based selection to generate a flop tray solution with mixed flop tray sizes.

Based on the generated flop trays, we then perform placement legalization, clock tree synthesis and routing. 
I will show an example in the next slide. 

SLIDE
As discussed, we first generate flop tray solution for each flop tray size. We then combine the solutions. 
This slide shows an example of our flow. 
The first three figures show the flop tray solutions with 4-bit, 16-bit and 64-bit flop trays. The last figure shows a combined solution from our ILP-based optimization. I will give details of our two-step optimization in the following slides. 

SLIDE
This slide describes our capacitated K-means clustering. Specifically, we solve the following problem. Given N points, which are locations of single-bit flops, a capacity K (which is defined by the flop size), we obtain N/K clusters to minimize the total displacement. 
Our flow is shown here. 

First, we select N/K initial points as centers. In this step, we first randomly select one flop among the single-bit flops. We then calculate the distance from each flop to all selected flops. We use the distance as probabilities to randomly select the next points. We iterative update the probabilities and select points until we select N/K points. 
Since the selection of initial points affects final solution quality and there is randomness in our optimization, we use multi-start technique in our optimization to achieve a better solution quality. 

Based on the selected centers, our K-means clustering iteratively performs clustering and center location update to generate flop tray solution. 

For clustering we formulate a min-cost flow to map single-bit flops to flop tray slots. The figure shows the flow network, where S and T are super source and sink. h are single-bit flops, f are slots on flop trays. 
The cost between a single-bit flop and a flop tray slot is the Manhattan distance between them. We note that by considering the distance between flops and slots, we are aware of the flop tray aspect ratios. 

To update the center locations, we formulate a linear program. Our LP simply minimizes the total displacements of flops as shown in the formulation. 

In our optimization, we iterate between the min-cost flow-based clustering and LP-based center location update until the center movement is negligible. 



SLIDE
Here is an example of our optimization. In blue are single-bit flops from an initial placement. In red are the center locations or flop tray locations. We use different colors to indicate different clusters. 

We can see that we start with randomly selected N/K centers. We then iteratively update the clustering and center location until the optimization converges. 

SLIDE
Recall that our optimization comprehends flop tray shapes by using distance between single-bit flops and slots in flop trays as cost in the clustering optimization. 
This slide compares our clustering solution which understands flop tray shapes versus a solution of the traditional K-means clustering which treats each flop tray as a point. 
The dots are single-bit flops and shaded rectangles are flop trays. We use different colors to indicate different clusters. 
We see that our clustering solution more closely matches the aspect ratio of the flop trays. 

SLIDE
Recall that we first generate flop tray solution for each flop tray sizes. We then formulate an integer linear program to combine the solutions with mixed flop tray sizes. This slide shows our ILP formulation. 
Our goal here is to minimize total displacement of flops, timing impact due to flop clustering and total flop tray cost such as number of flop trays and flop tray power. Here, W is the total cost of flop trays, which can be estimated based on their area or power, D is the total displacement, and Z is the total relative displacement of timing-critical start-end pairs. We minimize the relative displacement of timing-critical start-end pairs to minimize the timing impact of flop clustering. I will give details in the next slide. 
The first two constraints calculate flop displacement. 
These two constraints estimate total relative-displacement between timing-critical start-end flop pairs. 
This constraint calculates the cost of flop trays, where e is a binary indicator of whether a flop tray is used. 
The last constraint ensures that each flop has exactly on slot to match and each slot can have at most one flop to match. 
Note that since each single-bit flop only has a limited number of flop trays to match, the runtime of our ILP is small. In our experiments, the runtime is less than one minute of the VGA testcase with 17K flops and five candidate flop tray sizes. 
SLIDE 
Recall that there is a tradeoff between flop tray benefits versus the datapath power penalty. In our optimization, the choice of alpha in the objective function optimizes such a tradeoff. 
The figure shows numbers of flop trays with different sizes and average displacement of each flop vary with the alpha value. 
We see that when alpha is small, small-size flop trays are used and the displacement is small. On the other hand, when alpha is large, large-size flop trays are used and the displacement is large. 
In our experiments, we use several alpha values in the optimization and select the best outcome. 

SLIDE
Recall that we minimize the relative displacement to minimize timing impact. 
This slide illustrates our idea on the relative displacement. 
For a timing-critical start-end flop pair, relative displacement between them degrades timing. When they are moved apart, the delay will increase due to longer wire. When they are moved closer, there can be congestion in between. 
We therefore want to minimize the relative displacement of timing-critical start-end pairs. This figure shows our optimization results with different beta values. When beta is zero, we do not consider relative displacement. When beta is larger, we assign more weight to relative displacement in our objective function. We see from the result that by considering the relative displacement of timing-critical start-end pairs, we achieve 5% more power reduction. 

SLIDE
Now I will present our experimental results. 
This slide shows our experimental setup.
We perform experiments on four designs from opencores website.  
We use foundry 28 FDSOI dual-VT library. 
We use Design Compiler for synthesis, and Innovus for physical implementation and analysis. 
The bottom table shows our used flop trays. We have five flop tray sizes, ranges from 4-bit to 64-bit. Their normalized power and area as well as the aspect ratios are shown in the table.

SLIDE
This slide shows our experimental results. We compare to two reference flows. Ref_1b is the conventional implementation flow with only single-bit flops. ref_mb is the flop tray-based implementation with logical clustering during synthesis. Our optimization is  opt_mb. 
We can see that our optimization achieves up to 98% reduction clock tree sink number reduction, and 90% clock power reduction compared to the conventional single-bit flow. 
And 16% more total power reduction compared to the flow with logical clustering. 

SLIDE
This slide shows the example layouts before and after flop tray generation. In red are flops and in blue are combinational cells. We can see that different sizes of flop trays are used. For design MPEG, we can also see some white space near flop trays. That’s because flop trays are more area efficient than single-bit flops. This effect may also help to reduce routing congestion.

SLIDE
This slide shows optimization with various flop tray sizes. We create five combinations, with different bounds on the largest tray size. 
The figure shows clock power with different combinations of flop tray sizes normalized to the clock power with only single-bit flops. 
We can see that about 50% of clock power can be reduced by just applying 4-bit flop trays. 
With 16-bit or larger flop trays, we can achieve 11% more clock power reduction on average, especially on large designs.

SLIDE
We further study the useful skew optimization with flop trays. Useful skew is helpful to reduce datapath leakage power. However, application of flop trays will limit the benefits from useful skew optimization. We therefore modified our clustering approach to avoid clustering flops with large difference in desired latencies. 
More specifically, we calculate the optimal clock latency for each sink to maximize the slacks at each endpoint. We then avoid clustering flops with optimal required latency larger than a particular threshold. This enables skew-awareness.
From the table, we can see that we achieve similar leakage power compared to the solution with only single-bit flops, but at the cost of 21% less sink number reduction compared to our original flop tray-based solution.

SLIDE
Now I will give the conclusion. 
In this work, we propose a novel flop tray-based optimization with capacitated K-means algorithm. 
We achieve up to 16% total reduction compared to a conventional clustering flow. 
We also perform useful skew optimization in the context of flop tray based design. 
Our ongoing works include 
Scalable optimization considering all flop tray sizes at the same time.
And floorplan blockage awareness. 

Slide
My third topic for today’s presentation is floorplan and placement methodology for improved energy reduction in stacked power domain design. This is a joint work with NXP.

Slide
Battery lifetime is critical to IC designs, especially for IoT and mobile applications. 
But the misalignment between battery and core voltages can cause power inefficiency in voltage regulator. 
In this work, our goal is to improve the power delivery efficiency and to improve battery lifetime through stacked-domain optimization. 
A stacked-domain design connects two power domains with balanced current in series. 
Bottom figure illustrate the difference between a conventional design and a stacked-domain design. 
As an example, if the supply voltage of a conventional design is 1V. In the stacked-domain design, the VDD of the top domain is 2V, and VSS of the top domain is 1V, which is the same as the VDD of the bottom domain. 
With stacked domain, we can align the voltages between battery and the core and avoid power delivery inefficiency. 
Furthermore, current is recycled between two domains, which saves power.
 
Slide
This slide shows our problem formulation. 
Given netlist, timing constraints, level shifter timing and power models, voltage regulator efficiency and design power information, we partition the netlist into two domains, define layout region of each domain and place instances and level shifter. The objective here is to maximize battery lifetime of the design. 
However, the stacked-domain optimization is not trivial. There are several challenges. 
First, we have to ensure current balancing across multiple operating scenarios, such as function mode and sleep mode. 
Second, region generation for power domain will introduce layout constraints. We must minimize the corresponding overheads. 
Third, level shifter insertion will also incur power, area and timing penalties. We therefore want to minimize the number of level shifters. 

Slide
This slide shows our overall optimization flow. 
To achieve an estimation of the post-placement timing and current profile, we first perform a trial placement. 
We then perform flow-based partitioning with layout and timing-path awareness, and multi-scenario current balancing constraints. 
We then define regions for power domains. To reduce the complexity for power delivery network design and to minimize the area cost from gap insertion along the boundary between domains, we generate one continuous region for each power domain with minimized boundary length. 
Based on the defined region for each power domain, we then perform re-floorplaning and insert level shifters. 
Last, we perform placement optimization and incremental timing fix to remove timing violations caused by level shifter insertion.

Slide
This slide shows an example of our optimization flow. 
The first figure shows our flow-based partitioning solution which is layout aware. In blue are instances from the bottom domain and in red are instances from the top domain. 
In the second figure, we legalize the placement, define region for each power domain and optimize the boundary in between. 
In the last figure, we resize the floorplan and insert level shifters which are in yellow. 
I will give details of each optimization step in the following slides.

Slide
This slide shows the basic idea of flow-based partitioning. 
Our goal here is to perform current-balanced partitioning on the netlist with minimized number of cuts. 
In the partitioning flow, we first construct a flow network based on the netlist, where each cell or cluster of cells becomes a vertex, each net becomes an edge, and the weight of the vertex is estimated based on the current of the cell or cluster of cells. 
We then perform max-flow optimization, which gives the min-cut partitioning according to the max-flow min-cut theorem. 
After each max-flow optimization, if the currents between two partitions are not balanced, we cluster the nodes from the smaller partition, together with a neighbor note into one super vertex. We then perform another round of the max-flow optimization which gives a different partitioning solution. Note that clustering a neighbor nodes avoid the same partitioning solution in the second max-flow optimization. 
We iteratively perform max-flow optimization and clustering until currents are balanced between two partitions. 

The bottom figures show one example, where a and b are source and sink, and all nodes have the same weight. 
On this example, the first max-flow optimization finds the min cut a-c and a-e. But the currents are not balanced. So we cluster the smaller partition, which only has node a, and the randomly-selected neighbor e and perform the max-flow optimization again. The second max-flow optimization ends up with cuts ae-c and f-b. And the currents are balanced, so we have the final solution shown in the lower-left figure. 

However, this basic flow-based partitioning is not aware of cell placement and timing paths. So we propose several extensions in the next slides.
 
Slide 
To reduce the runtime and improve scalability of the flow-based partitioning, we propose a pre-clustering procedure. We perform heavy edge matching optimization, which simply clusters cells with dense connection, and use clusters instead of cells for flow-based partitioning optimization. The right figure shows in which different colors indicate different clusters. 
We also extend the flow-based partitioning to comprehend current balancing in multiple operating scenarios. For which, we use weighted sum of normalized currents from all scenarios as the balancing constraint.
To be aware of timing paths. We remove V-shaped vertices after each max-flow optimization. The right figure illustrates the V-shaped vertices, which are cells along one timing-critical path but across the boundary between two domains multiple times. 
Last, we enable the layout awareness by detecting and removing outliers after each max-flow optimization. Here, the outliers are instances from the large-current partition but located in the small-current region. 

Slide
Based on the partitioning solution, we define region for each power domain. Although our partitioning optimization is layout aware, there can still be separated regions for each power domain. These separated regions will increase the design complexity for power delivery network. So we want to have only one continuous region for each power domain. 
To achieve this, we perform a FM-based grid optimization to move cells. 
We first uniformly divide the block area into grids. 
We then find outliers, which are grid outside the largest continuous region of the same domain. For example, the yellow grids in the bottom figure. And neighbor grids, which are grids adjacent to the largest continuous region of a different domain. For example the green grids in the bottom figure.
Swapping pairs of outlier and neighbor grids will generate continuous region for each domain. But there is wirelength penalty. So we calculate the wirelength cost to swap of each pair of outlier and neighbor. 
We then select the pair with the minimum cost to swap. 
We iterate the swap moves until there is no outlier. 

Slide
In a stacked-domain design, gap area must be inserted along boundary between two domains. So we want to minimize the length of boundary to minimize area penalty. 
We propose a dynamic programming-based approach to optimize the boundary. 
We ensure that the area of each domain remains the same after our optimization, and the moved instance area are restricted. 
As discussed, the objective is to minimize the boundary length. 
Our DP formulation is shown here. We first index turning points from left to right along the boundary. We then optimize segment (1, j) by selecting the minimum-length combination of the optimized segment (1, i) and simplified segment (i, j) over all possible I values, while satisfying the constraints. 
The bottom figures show one example, where the red segment in the left figure is the original boundary, and blue segment in the right figure is the optimized boundary. 


Slide
Last, we insert level shifters. 
To generate space for level shifter insertion, we resize the floorplan by height of required level shifter rows. This also help to preserve the trial placement solution. 
We then enumerate candidate locations between two domains for level shifter insertion and perform matching-based optimization insert level shifter with minimized wirelength. 
This figure shows an example of floorplan resizing and level shifter insertion. 

Slide
This slide shows our experimental setup. We use four designs from opencores website and a dual-core M4 industrial design for our experiments. 
We use these tools for SP&R and timing, power analyses.
The bottom figure shows the power efficiency of voltage regulator. We see that the efficiency reduces with smaller current supply. 

Slide 18
This slide shows our experimental results. 
The figure shows battery lifetime of stacked domain designs normalized to those of conventional designs in both function and sleep mode. The table shows number of level shifters and current in top and bottom domains. 

We see that our stacked-domain optimization leads to more than 10% and 3X battery lifetime improvement in function and sleep mode respectively. 
And the currents are well balanced between top and bottom domains. 
The larger battery lifetime improvement in sleep mode compared to that in function mode is due to smaller current in sleep mode. 

Slide
We also apply the stacked-domain optimization to an industrial product design, which contains dual-core M4 MCU, modem and memories. In this optimization we also include clock tree synthesis. The right figure shows the optimized design. In red and blue are cells belong to bottom and top domains, and in white are level shifters. 
Based on our optimization, we achieve 15% and 2X battery lifetime improvement over the conventional design in function and sleep modes, respectively. 

We also explore the tradeoff between current balancing versus level shifter cost. The table shows three partitioning solutions with different delta current and number of level shifters. We evaluate the solutions with different regulator efficiency values. We see that when the voltage regulator efficiency is high, we want more balanced current; while smaller number of level shifters is preferred when the regulator efficiency is high. 
Slide
Now, I will give the conclusion. In this work, we propose the first comprehensive framework for stacked domain optimization. We extend the existing flow-based partitioning with several practical improvements. We achieve more than 10% and 3X battery lifetime improvement over the conventional designs in function and sleep modes. 
Our ongoing works include a predictive methodology to determine the block size, and optimization with more than two domains and/or in 3DICs.
 
 Slide 1:  Title
Thank you for the introduction. I am presenting this paper on behalf of my colleague Mr. Mulong Luo. This is a joint research work of UC San Diego and Samsung Electronics.

Slide 2: Outline
My talk is structured as follows. First, I provide background and motivation of the work. Second, I explain our crosstalk-aware layout optimization methods, followed by the testcase generation and experimental setup and results. Finally, I will conclude my talk.

Slide 3: Introduction
DRAM interconnect channels are regions used to connect the IO pad and DRAM arrays. These channels are narrow and long.
The channels contain many parallel wires, which can introduce large crosstalk. So, we must assign tracks to these wires so that the crosstalk does not cause large delay uncertainty. The manual, non-automated design is still the dominant methodology for the design of the DRAM channels. Manual track assignment might be far from optimal.
We propose an automated DRAM channel layout optimizer to minimize the crosstalk effects.

Slide 4: Related works (Word count: 87)
We review previous works in the areas of crosstalk-aware analysis and design.
In crosstalk-aware analysis, Xiao00 proposes analytical modeling of crosstalk-induced delay and noise.  Gross98 and Sato00 describe how the alignment of aggressor impacts crosstalk noise and delay on the victim.
In crosstalk-aware design, Yu09 propose a swizzling pattern to reduce crosstalk-induced delay.
Gao93 propose crosstalk-aware MILP-based detailed routing.
However, no existing works integrate simultaneous crosstalk-aware analysis and automated design. 
Slide 5: Our Contribution (Word count： 80)
Our key contributions are: 
First, we develop an accurate closed-form analytical delay uncertainty calculator.
Second, we integrate swizzling of signals in the channel to exploit signal correlation to reduce worst-case delay uncertainties. We propose MILP-based segment optimization and pair-swapping segment optimization methods.
We achieve up to 29% reduction of maximum weighted delay uncertainty compared to conventional methods.

Slide 6: Outline (word count: 10)
Now, I explain our crosstalk-aware layout optimizer.

Slide 7: Problem Statement (Word count: 116)
The inputs to our optimizer are: set of tracks T, set of segments G, set of signals S, and criticality classes of signals. 
Criticality denotes the priority of signal. For example, clock signal has the highest-criticality. Other inputs include design rules and inter-buffer lengths for each class. 
Our objective is to minimize the max weighted delay uncertainty among all signals in different classes.

Slide 8: Problem complexity (Word count: 107)
This problem is very complex. The size of the solution-space of exhaustive search is an astronomical number T permute S to the power of G. For example, a small testcase with 4 signals, 4 tracks on 4 segments have 331K possibilities.
To reduce the solution-space, we perform segment-by-segment optimization. Thus, we reduce the size to T permute S times G. For the same example, we now have 96 possibilities.
However, we pessimistically assume that the segments are not coupled. This is achieved by assigning infinite distance between wires. 
Slide 9: Segment-by-segment optimization (Word count: 100)
The figure explains why the assumption is pessimistic. When distance increases, the coupling cap will decrease, thus, the voltage change due to crosstalk on this segment will increase, which leads to increased delay uncertainty.
This assumption can lead to suboptimality, but according to our experiments, the suboptimality is negligible. We use the same example from the previous slide; additional parameters are listed here. The optimal results give maximum delay uncertainty of 7.16ps, whereas with segment-by-segment it is 7.19ps. Without any segment-by-segment optimization, we have 9.57ps. This shows the suboptimality of only 0.4 percent.



Slide 10: Overview of Crosstalk-Aware Layout Optimization (Word count: 71)
Given testcase specifications, we perform segment-by-segment optimization by either a MILP-based segment optimization or a pair swapping segment optimization.
The optimization is guided by out accurate and fast delay uncertainty calculator.

Slide 11: MILP-based Segment Optimization: Notations (Word count: 87)
I describe notations used in our MILP.
D_i is the delay uncertainty of signal at the input of current segment.
Delta_di_i’ is the estimated delta delay uncertainty of signal si at the end of the current segment when signal si’ is its neighbor.
lambda_l is a testcase-specific variable that represents the weight of class.
The output variables are q_ik and p_ii’, which are binary indicators for the assignment of signals and neighbors.

Slide 12: Basic constraints (Word count: 91)
Now I explain our constraints.  This constraint ensures that each signal occupies exactly one track.
Similarly, the second constraint forces that each track can only be occupied by at most one signal.
If signal I is on track k and signal I’ is on track k-1 or vice versa, then this constraint enforces that they are neighbors.
The last constraint makes sure that for |S| tracks, there will be at most |S|-1 pairs of neighbors. 

Slide 13: MILP-based segment optimization (Word count: 83)
We first pre-calculate the estimated delta delay uncertainty of all combinations of signal pairs using our calculator. 
Then, we assign the pre-calculated values in our formulation as shown in this constraint.
The objective is to minimize the max weighted delay uncertainty.
As an example, given 4 signals, our optimizer assigns the signals on the current segment. When it assigns the signals, it considers the estimated delta delay uncertainties of all pairs to minimize the delay uncertainty. 


Slide 14: Decomposition for Scalability (Word count: 154)
Our MILP can handle only up to 30 signal- and 30 track-sized channels. For the testcases with hundreds of signals, we propose the following decomposition method.
Let’s say the subset size we decompose is V. For the first segment, we ensure that the size is less than or equal to V.
For the subsequent segments, we offset the boundaries by V/2 so that signals from different subsets in the previous segment can be mixed to exploit the signal correlations.  
Now, we solve several MILP instances in parallel for each segment, which reduces runtime significantly.

Slide 15: Overview of Crosstalk-aware layout optimization (Word count: 12)
Now, I explain our pair-swapping segment optimization.

Slide 16: Pair-swapping Segment Optimization (Word count: 115)
For a large testcase, this method is faster and gives better max weighted delay uncertainty than MILP-based optimization with decomposition. 
The main idea of pair swapping is to swap signals with maximum weighted delay uncertainty with other signals.
First, we sort all the signals by the increasing order of delay uncertainty.
Second, we swap the signals with max-weighted delay uncertainty and the signals with min-weighted delay uncertainty. Then, check the max-weighted delay uncertainty. If no improvement is seen, we revert the swapping. Otherwise we keep the swap.
We repeat the steps 1, 2 until there is no improvement.

Slide 17: Overview of crosstalk-aware layout optimization (Word count: 12)
Now, I describe our delay uncertainty calculator.

============================================
Slide 18: Delay Uncertainty Calculator (words:  107)
Long runtime is a well-known limitation of SPICE simulations. To overcome this limitation, we have developed a fast closed-form delay uncertainty calculator. 
For a given aggressor-victim pair, we generate noise waveform induced by crosstalk using a 2pi circuit. We then measure the impact of noise on dynamic delay change of the victim signal. This is called delay change curve proposed in Sato03. Finally, we get the delay uncertainty of victim signal from DCC. For multiple signals, we calculate delay uncertainties for all neighboring pairs and superpose them. 

Slide 19: Accuracy of Delay Uncertainty Model (words:  99)
Here, we compare our model and the model in Gupta04.
We generate 300 random swizzling patterns for a simple testcase with 5 signals, 5 tracks and a 8000um channel divided into 8 segments. We then correlate ranks with SPICE simulation results. The left figure shows rank correlation between our model and SPICE. And, right figure shows the rank correlation between Gupta04 model and SPICE. We see that our model shows much better correlations to the SPICE results. 

Slide 20: Outline
Now, I explain how we generate artificial, but realistic testcases.

Slide 21: Testcase Generation: General Inputs (words: 145)
To our knowledge, there is no public benchmark to study DRAM channel routing problems. So, we develop a testcase generator guided by an engineer in a leading DRAM manufacturer.  There are three types of inputs to the generator; general inputs, class-specific inputs and signal-specific inputs.  
Here, I will discuss the general inputs.  Channel length, channel width, number of signals, number of tracks and number of segments are required as shown this figure. We also need a probability table that correlates signals between all pairs of classes. For example, a value of 1 means in Row 2 Column 3 that all signals in class 0 are correlated with all signals in class 1. We assume if any two signals are correlated, their timing window could be overlapped.  Supply voltage and clock period are also provided as general inputs to our testcase generator. 

Slide 22: Testcase Generation: More Inputs (words: 136)
Here is the list of class-specific inputs which include the number of signals in each class,  ground cap and resistance per micron. There are different coupling capacitances per micron among signals in different classes since the signals in different classes follow different width and spacing rules. In our optimization, the distance between two consecutive buffers is fixed. We are also given the input pin capacitance and the drive resistance of buffers as inputs. 
Last, there are signal-specific inputs. It includes load cap., resistance at signal input, input slew and correlation with other signals. Correlation between any two signals is determined by the probability table that I described in previous slide.  If any two signals are correlated, we assume their timing windows are overlapped and the signals switch in different directions.

Slide 23: Outline
Now, I describe our experimental setup and results.

Slide 24: Experimental Setup (words: 154)
We use a fixed channel length 8000um for all testcases. We use signals with five classes. Pitch, width, space and buffer locations are shown in this table. Class 0 is the highest criticality class. Other signal-specific inputs are shown here.
We conduct a total of four experiments. In Experiments 1, 2 and 3, we study the impact of different input conditions on delay uncertainty using small testcases. We vary the number of signals, the number of tracks and the correlation between signals, and observe how our optimizer delivers different layout solutions. 
In Experiment 4, we compare MILP, pair-swapping and signal permutation methods with larger and more realistic testcases. I will explain the details as part of the experimental results. 

Slide 25: Experiment 1: Impact of Number of Signals and Tracks (words: 163)
We vary the number of signals and tracks to see the impact of these on delay uncertainty. In this experiment, we use the weights of the five classes as 10, 6.7, 4, 2, 1. 10 is used for the highest-criticality class and 1 is used for the lowest-criticality class. The number of signals for each class is the same. For example, testcase E1T1 has two signals in each class.
These are the results of testcase E1T1. The lower-left figure shows the change of delay uncertainty in the Y-axis and channel distance in the X-axis for each class. We see the signals in the higher-criticality class achieve smaller delay uncertainty. 
This figure shows the final layout solution. The thickness represents delay uncertainty. I want to note that the signals in the highest-criticality class are mostly on the boundary of the channel to minimize the delay uncertainty.   

Slide 26: Experiment2: Impact of Percentage of Signals in Each Class (words: 96)
Here, we use a fixed number of signals and tracks which is 20 and only vary the percentage of signals in different classes. We use the same weights used in Experiment1.  The table shows the priority and number of signals together with the maximum delay uncertainty of each class and objective function value. 
We see that the objective value reduces if the percentage of lower-criticality signals increases.  Also, when we change class B to lower priority, the max delay uncertainty of signals in class A reduces accordingly.  

Slide 27: Experiment3: Impact of Correlation of Signals (words: 115)
In this experiment, we set the number of signals and tracks as five. We generate two testcases E3T1 and E3T2. Both have four signals in the higher-criticality class and one signal in the lower-criticality class. In E3T1, signals in different classes are fully correlated, but in E3T2, signals in different classes are not correlated.
Below figures show the layout solutions. Orange-colored signal is in the lower-criticality class. We observe that the orange-colored signal in E3T2 is routed in the middle of channel. This maximizes the mutual shielding effect to minimize delay uncertainty. As a result, we see that the maximum delay uncertainty of signals in E3T1 is larger than that in E3T2. 

Slide 28: Experiment4: MILP vs. Pair-Swapping vs. Signal Permutation (1) (words: 109)
To evaluate our methods with more realistic testcases, we generate larger four testcase T2 to T5. The number of tracks and the number of signals in each class are shown here. Testcases T3 and T5 have some empty tracks to study the impact of the empty tracks. The size of decomposition subset of MILP-based method is 20. 
Overall, pair-swapping method shows better results than signal permutation. It shows up to 29% reduction of maximum weighted delay uncertainty. With empty tracks in T3 and T5, delay uncertainty is reduced by up to 19.9%. Also, pair-swapping run faster than MILP-based method.

Slide 30: Outline
Now, I conclude my talk.

Slide 31: Conclusion
In this work, we propose a DRAM routing channel optimizer to specifically target the layout design of long, resource-constrained channels in modern DRAM products.
Our optimizer is signal criticality-aware, and minimizes a maximum weighted delay uncertainty.
We achieve up to 29% reduction of maximum weighted delay uncertainty compared to a traditional track permutation methodology.
Our ongoing work includes flexible buffer location and use of inverters to further reduce delay uncertainty.
SLIDE 1: TITLE
Thank you for the introduction. This is a joint work of UCSD and Qualcomm Research.
SLIDE 2: OUTLINE
My talk is structured as follows. I begin with motivation. 
SLIDE 3: 3DIC VALUE PROPOSITION
As the semiconductor industry nears the end of the CMOS roadmap, 3DICs have emerged as a promising solution to continue Moore’s Law trajectory of value scaling. 3DICs are fundamental to the whole idea of More than Moore. In the context of this work, power reduction benefit is the key value proposition for 3DICs. 3D power estimation tools are required to enable fast and accurate implementation-space exploration to evaluate power benefits of 3DICs.
SLIDE 4: 3D POWER ESTIMATION CHALLENGES
3D power estimation is challenging because the benefit varies with netlist topologies, constraints, etc.. Moreover, no golden 3D implementation flow exists. This introduces a chicken-and-egg loop because we are trying to embed netlists not created for 3D into 3D. Therefore, we can only rely on 2D implementations for 3D guidance. 
But, no tool exists today that predicts 3D power benefits based on 2D implementations.
SLIDE 5: OUTLINE
In the context of this work, 
SLIDE 6: 3D PRELIMINARIES
This figure shows a classic 2DIC. The height and width of the die are H and W, respectively. When this implementation is changed to 3DIC, we can create two vertically stacked dies. The height and width of each die is divided by the square root of two with respect to those of the 2DIC. The dies are interconnected by vertical interconnects.
Shrunk2D is another way to emulate a 3DIC by doing P&R in a die with the same height and width of the 3DIC.  This flow proposed by Panth et al. is the best “3D” flow today. 
SLIDE 7: 3D POWER ESTIMATION TOOL
The implementation-space of a 3DIC is high-dimensional. Multiple choices are available in setting constraints such as timing and design rules, layout contexts such as aspect ratio, utilization, EDA tool flows, and technology choices such as Vt flavors, libraries, etc.
Therefore, we need an accurate power estimation tool to quickly determine the best set of parameters from this high-dimensional space that delivers 3D power benefits.
SLIDE 8: KEY CONTRIBUTIONS
In this work, we provide a tight upper bound on 3D wirelength reduction. 
We are the first to develop a 3D power benefits estimation tool, 3DPE based on 2D implementations. We predict the percentage delta power benefits of 3DIC relative to 2DIC implementations. The error range of our predictions is within 10%. 
We propose a novel parameter selection methodology based on sensitivity of SP&R outcomes to wireload model and RC scaling. This is an unexplored approach to assess how gate-level netlists will react to 3D vs. 2D implementation contexts.

We propose a “stress testing” validation approach and application of 3DPE in model-guided implementation. 
SLIDE 9: FLOW IMPROVEMENTS
We use the latest Shrunk2D or S2D flow from Georgia Tech as our baseline. We have transplanted the flow and replicated published results at UCSD.
We have enhanced the S2D flow in various ways. 
SLIDE 10: OUTLINE
What is an upper bound on the wirelength reduction in 3D?
SLIDE 11: TIGHT UPPER BOUND ON 3DIC WL BENEFITS (1)?
The figure on the left shows a 3D grid graph with net n1 in red color. The right-figure shows the cross-section view of the net. Our cost model is as follows. The Z-direction cost is zero because the heights of vertical interconnects are assumed to be very small in 3DIC. X, Y cost is 1 unit per hop. 
Key 1 of this derivation is we start with an optimal 3D routing; hence the reduction is an upper bound. Key 2 is without loss of generality, we can stretch the graph arbitrarily in one direction, and hence the bound is tight. Therefore, this example shows a tight upper bound.
The length of net n1 is therefore, 1 due to the segment BC.


SLIDE 12: TIGHT UPPER BOUND ON 3DIC WL BENEFITS (2)?
Net n1 becomes net n1’ in 2D and its length is 3 due to 3 hops between segments AB, BC and CD. The wirelength reduction is therefore 66.7%.
In our experiments, we do not explore RC scaling factors below 33.3% as guidance from this bound.

SLIDE 13: OUTLINE
Next, I describe our modeling methodology.
SLIDE 14: TESTCASES AND IMPLEMENTATION
We use a wide range of IPs that resembles building blocks of modern SoCs. The table shows the list of our testcases. We use five types of testcases -- CPU, GPU, modem, multimedia and peripheral engine. 
SLIDE 15: IMPLEMENTATION-SPACE PARAMETERS
Here is list of various implementation-space parameters we use in our experiments. The parameters span across various constraints, layout contexts and technology choices.
SLIDE 16: FLOW AND TOP-10 MODELING PARAMETERS
However, to restrict the dimensionality and runtime of our modeling problem, we seek to explore the 10 most influential parameters. 
In our flow, we use engineered WLMs to perform synthesis. Then, we perform both 2D and Shrunk2D P&R. We use S2D as a proxy for 3D. 
For both P&R flows, we use scaled RC cap tables. We then extract parameters for modeling.
The top-10 parameters include six constraints such as clock period, max transition time, etc. We also use two implementation and two technology parameters such as utilization, multi-Vt libraries, respectively.  
SLIDE 17: MACHINE LEARNING METHODOLOGY
With parameters extracted from 2DIC implementation, we perform modeling. We use artificial neural networks to capture the complex interactions between parameters.  
We define the ANN architecture with one input and one output layer, plus two hidden layers. We search for the best number of the epochs of back propagation and the number of neurons per layer using the loop here to achieve bounded errors. 
We obtain our ground truth from S2D runs. 
SLIDE 18: OUTLINE
Now, I present our results.
SLIDE 19: BOUNDED-ERROR MODELS
This plot shows the actual percentage delta power benefit in the X-axis and the predicted values in the Y-axis for the five types of testcases. We derive separate models for each of the power components – internal, switching and leakage. Then we compose these models to create a model for total power.
We challenge ourselves to predict delta power. Consider this example in which 2DIC power is 90mW and the corresponding 3DIC power is 80mW. The delta is 10mW. To achieve 10% error on actual 3DIC power, the predictions can range between 72mW to 88mW. However, to achieve 10% error on the delta, the predictions must range between 79mW to 81mW. This is a difficult task.
Across all our test data points, the range of errors is 9%. 
SLIDE 20: NOVEL “STRESS-TESTING”
We do not have ground truth from true 3DIC implementations, so we must test if our 3DPE models are capable of returning unlikely predictions. 
We perform “stress testing” of the models. We perform Monte Carlo-like simulations by varying the mean and variance of each parameter in the models.
The figure shows a histogram of percentage predicted delta power. The maximum value is 39% for data points that are practically realizable. 
We reject data points that are not practically realizable. For example, data points in which the number of cells, utilization and the cell area are mismatched. Or, the wirelength and the number of cells are mismatched. 

SLIDE 21: MODEL-GUIDED IMPLEMENTATION
The hypothesis here is 3DPE should guide implementation if the predictions are reliable. We refer to this as model-guided implementation. We test this hypothesis with an implementation here.  This figure shows WLM cap in the X-axis and 3D power in the Y-axis. Minimum 3D power is achieved at 0.45pF. Our models predict the cap to be 0.75pF, using which the delta power is 0.34mW. Therefore, 3DPE model guidance is better than S2D by 5%. 
SLIDE 20: OUTLINE


SLIDE 22: SUMMARY
In summary, power reduction is a key value proposition for 3DICs. Lack of a golden 3D flow makes prediction of 3D power benefits a difficult problem. 
We develop the 3DPE tool that predicts the percentage delta power benefits of 3DIC relative to 2DIC implementations. 3DPE is accurate with an error range of 10%. 
We also propose stress testing and model-guided implementation approaches with 3DPE. Our ongoing works include extending 3DPE from block-level to SoC-level predictions and developing a true 3D flow. 
SLIDE 23: ACKNOWLEDGMENTS
We thank Prof. Zelikovsky, Prof. Lim, Dr. Panth and Dr. Jung for various discussions and generosity in flow development at UCSD. 
SLIDE 24: THANK YOU
Thank you for your attention. 